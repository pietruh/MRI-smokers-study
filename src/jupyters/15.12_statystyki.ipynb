{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('/Users/zosia/Desktop/dane_prom/fully_merged_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Find ID of strange data (smoker with 0 years of smoking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_stats = pd.read_excel('/Users/zosia/Desktop/dane_prom/all_stats_eng.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strange = all_stats.loc[(all_stats['group'] == 'non') | all_stats['YearsOfSmoking'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "strange_id = strange.Variables.str.extract('(\\d+)')\n",
    "strange_id = strange_id[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 637)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data= df.iloc[:,[0,40]]\n",
    "#data = df[list(df.columns[0:1]) + list(df.columns[40:])]\n",
    "data = df\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_id = [130, 361, 379, 382, 455, 508, 517, 566, 643, 801, 834, 854, 927, 513] # + strange_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130, 361, 379, 382, 455, 508, 517, 566, 643, 801, 834, 854, 927, 513]\n"
     ]
    }
   ],
   "source": [
    "print( drop_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data[~data.id.isin(drop_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 637)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>L Cortex White Surface Total Area</th>\n",
       "      <th>L Cortex Mean Thickness</th>\n",
       "      <th>L Brain Segmentation Volume</th>\n",
       "      <th>L Brain Segmentation Volume Without Ventricles</th>\n",
       "      <th>L  Brain Segmentation Volume Without Ventricles from Surf</th>\n",
       "      <th>R Cortex White Surface Total Area</th>\n",
       "      <th>R Cortex Mean Thickness</th>\n",
       "      <th>R  Brain Segmentation Volume</th>\n",
       "      <th>R Brain Segmentation Volume Without Ventricles</th>\n",
       "      <th>...</th>\n",
       "      <th>normRange3</th>\n",
       "      <th>BrainStem_index</th>\n",
       "      <th>BrainStem_SegId</th>\n",
       "      <th>BrainStem_Nvoxels</th>\n",
       "      <th>BrainStem_volume_mm3</th>\n",
       "      <th>normMean4</th>\n",
       "      <th>normStdDev3</th>\n",
       "      <th>normMin3</th>\n",
       "      <th>normMax3</th>\n",
       "      <th>normRange2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>91559.1</td>\n",
       "      <td>2.66137</td>\n",
       "      <td>1266925</td>\n",
       "      <td>1248772</td>\n",
       "      <td>1.248798e+06</td>\n",
       "      <td>92652.3</td>\n",
       "      <td>2.67640</td>\n",
       "      <td>1266925</td>\n",
       "      <td>1248772</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>22857</td>\n",
       "      <td>22904.9</td>\n",
       "      <td>77.7730</td>\n",
       "      <td>9.7718</td>\n",
       "      <td>13</td>\n",
       "      <td>113</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>87801.8</td>\n",
       "      <td>2.59872</td>\n",
       "      <td>1191311</td>\n",
       "      <td>1177870</td>\n",
       "      <td>1.177810e+06</td>\n",
       "      <td>87335.4</td>\n",
       "      <td>2.62856</td>\n",
       "      <td>1191311</td>\n",
       "      <td>1177870</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>18257</td>\n",
       "      <td>18139.2</td>\n",
       "      <td>82.3428</td>\n",
       "      <td>9.6367</td>\n",
       "      <td>19</td>\n",
       "      <td>113</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000</td>\n",
       "      <td>84704.4</td>\n",
       "      <td>2.63064</td>\n",
       "      <td>1129977</td>\n",
       "      <td>1116423</td>\n",
       "      <td>1.116157e+06</td>\n",
       "      <td>85373.0</td>\n",
       "      <td>2.62956</td>\n",
       "      <td>1129977</td>\n",
       "      <td>1116423</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>19200</td>\n",
       "      <td>19226.5</td>\n",
       "      <td>82.9126</td>\n",
       "      <td>9.6400</td>\n",
       "      <td>18</td>\n",
       "      <td>111</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>100968.0</td>\n",
       "      <td>2.63486</td>\n",
       "      <td>1362391</td>\n",
       "      <td>1345462</td>\n",
       "      <td>1.345388e+06</td>\n",
       "      <td>101887.0</td>\n",
       "      <td>2.59180</td>\n",
       "      <td>1362391</td>\n",
       "      <td>1345462</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>21958</td>\n",
       "      <td>21924.0</td>\n",
       "      <td>82.6825</td>\n",
       "      <td>9.1148</td>\n",
       "      <td>21</td>\n",
       "      <td>115</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103</td>\n",
       "      <td>79255.4</td>\n",
       "      <td>2.67144</td>\n",
       "      <td>1059360</td>\n",
       "      <td>1046824</td>\n",
       "      <td>1.046769e+06</td>\n",
       "      <td>78432.2</td>\n",
       "      <td>2.66245</td>\n",
       "      <td>1059360</td>\n",
       "      <td>1046824</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>18079</td>\n",
       "      <td>17879.4</td>\n",
       "      <td>80.9856</td>\n",
       "      <td>9.8699</td>\n",
       "      <td>21</td>\n",
       "      <td>112</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>79338.6</td>\n",
       "      <td>2.56434</td>\n",
       "      <td>1176364</td>\n",
       "      <td>1161059</td>\n",
       "      <td>1.160913e+06</td>\n",
       "      <td>80724.6</td>\n",
       "      <td>2.57059</td>\n",
       "      <td>1176364</td>\n",
       "      <td>1161059</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>22930</td>\n",
       "      <td>22734.0</td>\n",
       "      <td>84.5854</td>\n",
       "      <td>9.2122</td>\n",
       "      <td>20</td>\n",
       "      <td>118</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128</td>\n",
       "      <td>78525.1</td>\n",
       "      <td>2.68181</td>\n",
       "      <td>1071264</td>\n",
       "      <td>1054853</td>\n",
       "      <td>1.055068e+06</td>\n",
       "      <td>78855.4</td>\n",
       "      <td>2.66719</td>\n",
       "      <td>1071264</td>\n",
       "      <td>1054853</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>17410</td>\n",
       "      <td>17277.2</td>\n",
       "      <td>85.8374</td>\n",
       "      <td>9.7606</td>\n",
       "      <td>24</td>\n",
       "      <td>118</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>87890.2</td>\n",
       "      <td>2.59890</td>\n",
       "      <td>1140328</td>\n",
       "      <td>1129039</td>\n",
       "      <td>1.129032e+06</td>\n",
       "      <td>87944.7</td>\n",
       "      <td>2.61157</td>\n",
       "      <td>1140328</td>\n",
       "      <td>1129039</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>18974</td>\n",
       "      <td>18929.3</td>\n",
       "      <td>82.2677</td>\n",
       "      <td>9.9673</td>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>131</td>\n",
       "      <td>94714.7</td>\n",
       "      <td>2.54105</td>\n",
       "      <td>1247199</td>\n",
       "      <td>1229357</td>\n",
       "      <td>1.229742e+06</td>\n",
       "      <td>95115.3</td>\n",
       "      <td>2.51661</td>\n",
       "      <td>1247199</td>\n",
       "      <td>1229357</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>24174</td>\n",
       "      <td>24133.4</td>\n",
       "      <td>80.6521</td>\n",
       "      <td>9.4648</td>\n",
       "      <td>17</td>\n",
       "      <td>111</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>132</td>\n",
       "      <td>98049.4</td>\n",
       "      <td>2.65850</td>\n",
       "      <td>1409536</td>\n",
       "      <td>1339095</td>\n",
       "      <td>1.338803e+06</td>\n",
       "      <td>99493.8</td>\n",
       "      <td>2.65336</td>\n",
       "      <td>1409536</td>\n",
       "      <td>1339095</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>23817</td>\n",
       "      <td>23681.6</td>\n",
       "      <td>79.6083</td>\n",
       "      <td>10.1321</td>\n",
       "      <td>14</td>\n",
       "      <td>116</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>133</td>\n",
       "      <td>103685.0</td>\n",
       "      <td>2.57657</td>\n",
       "      <td>1398236</td>\n",
       "      <td>1378903</td>\n",
       "      <td>1.379042e+06</td>\n",
       "      <td>102384.0</td>\n",
       "      <td>2.58776</td>\n",
       "      <td>1398236</td>\n",
       "      <td>1378903</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>25079</td>\n",
       "      <td>24981.5</td>\n",
       "      <td>77.2783</td>\n",
       "      <td>8.9300</td>\n",
       "      <td>12</td>\n",
       "      <td>110</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>134</td>\n",
       "      <td>85282.2</td>\n",
       "      <td>2.68347</td>\n",
       "      <td>1165461</td>\n",
       "      <td>1146992</td>\n",
       "      <td>1.146684e+06</td>\n",
       "      <td>87742.9</td>\n",
       "      <td>2.61131</td>\n",
       "      <td>1165461</td>\n",
       "      <td>1146992</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>20944</td>\n",
       "      <td>20973.5</td>\n",
       "      <td>77.2457</td>\n",
       "      <td>9.1203</td>\n",
       "      <td>17</td>\n",
       "      <td>104</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>135</td>\n",
       "      <td>93135.4</td>\n",
       "      <td>2.66900</td>\n",
       "      <td>1271889</td>\n",
       "      <td>1251653</td>\n",
       "      <td>1.251647e+06</td>\n",
       "      <td>93052.1</td>\n",
       "      <td>2.67368</td>\n",
       "      <td>1271889</td>\n",
       "      <td>1251653</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>21204</td>\n",
       "      <td>21122.4</td>\n",
       "      <td>85.6754</td>\n",
       "      <td>10.1301</td>\n",
       "      <td>31</td>\n",
       "      <td>115</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>136</td>\n",
       "      <td>85523.8</td>\n",
       "      <td>2.75854</td>\n",
       "      <td>1197918</td>\n",
       "      <td>1188653</td>\n",
       "      <td>1.188462e+06</td>\n",
       "      <td>83964.4</td>\n",
       "      <td>2.78450</td>\n",
       "      <td>1197918</td>\n",
       "      <td>1188653</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>24582</td>\n",
       "      <td>24544.6</td>\n",
       "      <td>79.4582</td>\n",
       "      <td>9.0830</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>138</td>\n",
       "      <td>95111.7</td>\n",
       "      <td>2.65536</td>\n",
       "      <td>1312880</td>\n",
       "      <td>1295654</td>\n",
       "      <td>1.295472e+06</td>\n",
       "      <td>95071.0</td>\n",
       "      <td>2.61290</td>\n",
       "      <td>1312880</td>\n",
       "      <td>1295654</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>26103</td>\n",
       "      <td>25818.9</td>\n",
       "      <td>80.1656</td>\n",
       "      <td>9.1385</td>\n",
       "      <td>15</td>\n",
       "      <td>123</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>139</td>\n",
       "      <td>75033.5</td>\n",
       "      <td>2.52904</td>\n",
       "      <td>1019349</td>\n",
       "      <td>1012515</td>\n",
       "      <td>1.012630e+06</td>\n",
       "      <td>74049.8</td>\n",
       "      <td>2.53346</td>\n",
       "      <td>1019349</td>\n",
       "      <td>1012515</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>20369</td>\n",
       "      <td>20192.8</td>\n",
       "      <td>84.6042</td>\n",
       "      <td>9.5492</td>\n",
       "      <td>22</td>\n",
       "      <td>110</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>140</td>\n",
       "      <td>103796.0</td>\n",
       "      <td>2.60240</td>\n",
       "      <td>1363925</td>\n",
       "      <td>1340839</td>\n",
       "      <td>1.341556e+06</td>\n",
       "      <td>104259.0</td>\n",
       "      <td>2.57490</td>\n",
       "      <td>1363925</td>\n",
       "      <td>1340839</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>23794</td>\n",
       "      <td>23929.5</td>\n",
       "      <td>76.7749</td>\n",
       "      <td>9.6350</td>\n",
       "      <td>5</td>\n",
       "      <td>127</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>141</td>\n",
       "      <td>80641.1</td>\n",
       "      <td>2.55906</td>\n",
       "      <td>1102551</td>\n",
       "      <td>1082833</td>\n",
       "      <td>1.082708e+06</td>\n",
       "      <td>80701.8</td>\n",
       "      <td>2.56191</td>\n",
       "      <td>1102551</td>\n",
       "      <td>1082833</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>20636</td>\n",
       "      <td>20730.0</td>\n",
       "      <td>83.4055</td>\n",
       "      <td>10.6106</td>\n",
       "      <td>20</td>\n",
       "      <td>120</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>142</td>\n",
       "      <td>94488.5</td>\n",
       "      <td>2.63243</td>\n",
       "      <td>1257434</td>\n",
       "      <td>1244847</td>\n",
       "      <td>1.245186e+06</td>\n",
       "      <td>94124.9</td>\n",
       "      <td>2.58778</td>\n",
       "      <td>1257434</td>\n",
       "      <td>1244847</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>22795</td>\n",
       "      <td>22807.3</td>\n",
       "      <td>77.3085</td>\n",
       "      <td>9.0503</td>\n",
       "      <td>20</td>\n",
       "      <td>109</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>143</td>\n",
       "      <td>83619.1</td>\n",
       "      <td>2.62288</td>\n",
       "      <td>1091656</td>\n",
       "      <td>1068422</td>\n",
       "      <td>1.068585e+06</td>\n",
       "      <td>82517.5</td>\n",
       "      <td>2.59367</td>\n",
       "      <td>1091656</td>\n",
       "      <td>1068422</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>18719</td>\n",
       "      <td>18765.1</td>\n",
       "      <td>81.1326</td>\n",
       "      <td>9.9091</td>\n",
       "      <td>12</td>\n",
       "      <td>133</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>145</td>\n",
       "      <td>83386.2</td>\n",
       "      <td>2.52836</td>\n",
       "      <td>1111972</td>\n",
       "      <td>1094242</td>\n",
       "      <td>1.093683e+06</td>\n",
       "      <td>82724.4</td>\n",
       "      <td>2.54718</td>\n",
       "      <td>1111972</td>\n",
       "      <td>1094242</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>19803</td>\n",
       "      <td>19577.4</td>\n",
       "      <td>86.4223</td>\n",
       "      <td>9.6733</td>\n",
       "      <td>22</td>\n",
       "      <td>131</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>146</td>\n",
       "      <td>84920.7</td>\n",
       "      <td>2.55846</td>\n",
       "      <td>1209213</td>\n",
       "      <td>1180240</td>\n",
       "      <td>1.180156e+06</td>\n",
       "      <td>86456.5</td>\n",
       "      <td>2.56250</td>\n",
       "      <td>1209213</td>\n",
       "      <td>1180240</td>\n",
       "      <td>...</td>\n",
       "      <td>101</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>20122</td>\n",
       "      <td>19987.5</td>\n",
       "      <td>81.9762</td>\n",
       "      <td>9.9796</td>\n",
       "      <td>12</td>\n",
       "      <td>127</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>147</td>\n",
       "      <td>94609.5</td>\n",
       "      <td>2.58726</td>\n",
       "      <td>1260721</td>\n",
       "      <td>1244787</td>\n",
       "      <td>1.244942e+06</td>\n",
       "      <td>94792.2</td>\n",
       "      <td>2.61917</td>\n",
       "      <td>1260721</td>\n",
       "      <td>1244787</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>21757</td>\n",
       "      <td>21616.2</td>\n",
       "      <td>76.4430</td>\n",
       "      <td>8.8578</td>\n",
       "      <td>14</td>\n",
       "      <td>111</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>148</td>\n",
       "      <td>79669.2</td>\n",
       "      <td>2.55312</td>\n",
       "      <td>1084902</td>\n",
       "      <td>1061281</td>\n",
       "      <td>1.061293e+06</td>\n",
       "      <td>80421.2</td>\n",
       "      <td>2.50960</td>\n",
       "      <td>1084902</td>\n",
       "      <td>1061281</td>\n",
       "      <td>...</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>18759</td>\n",
       "      <td>18643.5</td>\n",
       "      <td>87.1677</td>\n",
       "      <td>9.4922</td>\n",
       "      <td>23</td>\n",
       "      <td>119</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>149</td>\n",
       "      <td>93475.0</td>\n",
       "      <td>2.54315</td>\n",
       "      <td>1255548</td>\n",
       "      <td>1240815</td>\n",
       "      <td>1.240710e+06</td>\n",
       "      <td>95572.9</td>\n",
       "      <td>2.50041</td>\n",
       "      <td>1255548</td>\n",
       "      <td>1240815</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>20518</td>\n",
       "      <td>20418.3</td>\n",
       "      <td>80.0462</td>\n",
       "      <td>9.0043</td>\n",
       "      <td>17</td>\n",
       "      <td>127</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15</td>\n",
       "      <td>81820.6</td>\n",
       "      <td>2.58990</td>\n",
       "      <td>1118911</td>\n",
       "      <td>1102769</td>\n",
       "      <td>1.102539e+06</td>\n",
       "      <td>82296.2</td>\n",
       "      <td>2.56846</td>\n",
       "      <td>1118911</td>\n",
       "      <td>1102769</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>19331</td>\n",
       "      <td>19394.6</td>\n",
       "      <td>81.9146</td>\n",
       "      <td>9.9756</td>\n",
       "      <td>10</td>\n",
       "      <td>119</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>150</td>\n",
       "      <td>81003.9</td>\n",
       "      <td>2.56500</td>\n",
       "      <td>1114273</td>\n",
       "      <td>1104168</td>\n",
       "      <td>1.104022e+06</td>\n",
       "      <td>80895.5</td>\n",
       "      <td>2.55624</td>\n",
       "      <td>1114273</td>\n",
       "      <td>1104168</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>22105</td>\n",
       "      <td>21936.8</td>\n",
       "      <td>80.2958</td>\n",
       "      <td>8.6282</td>\n",
       "      <td>18</td>\n",
       "      <td>108</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>151</td>\n",
       "      <td>85433.2</td>\n",
       "      <td>2.66207</td>\n",
       "      <td>1178838</td>\n",
       "      <td>1165048</td>\n",
       "      <td>1.164786e+06</td>\n",
       "      <td>86921.9</td>\n",
       "      <td>2.63077</td>\n",
       "      <td>1178838</td>\n",
       "      <td>1165048</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>19878</td>\n",
       "      <td>19861.2</td>\n",
       "      <td>84.2946</td>\n",
       "      <td>9.3110</td>\n",
       "      <td>22</td>\n",
       "      <td>123</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>152</td>\n",
       "      <td>90496.6</td>\n",
       "      <td>2.65899</td>\n",
       "      <td>1192808</td>\n",
       "      <td>1176554</td>\n",
       "      <td>1.175949e+06</td>\n",
       "      <td>90155.1</td>\n",
       "      <td>2.69232</td>\n",
       "      <td>1192808</td>\n",
       "      <td>1176554</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>19866</td>\n",
       "      <td>19772.3</td>\n",
       "      <td>82.1009</td>\n",
       "      <td>9.6893</td>\n",
       "      <td>12</td>\n",
       "      <td>118</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>153</td>\n",
       "      <td>88420.0</td>\n",
       "      <td>2.54916</td>\n",
       "      <td>1211413</td>\n",
       "      <td>1198000</td>\n",
       "      <td>1.198011e+06</td>\n",
       "      <td>89815.2</td>\n",
       "      <td>2.55794</td>\n",
       "      <td>1211413</td>\n",
       "      <td>1198000</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>23252</td>\n",
       "      <td>23064.6</td>\n",
       "      <td>83.8896</td>\n",
       "      <td>9.1852</td>\n",
       "      <td>32</td>\n",
       "      <td>122</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>939</td>\n",
       "      <td>86099.0</td>\n",
       "      <td>2.52789</td>\n",
       "      <td>1151328</td>\n",
       "      <td>1137121</td>\n",
       "      <td>1.136990e+06</td>\n",
       "      <td>88603.4</td>\n",
       "      <td>2.48837</td>\n",
       "      <td>1151328</td>\n",
       "      <td>1137121</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>21112</td>\n",
       "      <td>21139.4</td>\n",
       "      <td>80.8985</td>\n",
       "      <td>10.0290</td>\n",
       "      <td>13</td>\n",
       "      <td>122</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>940</td>\n",
       "      <td>93159.3</td>\n",
       "      <td>2.61385</td>\n",
       "      <td>1261587</td>\n",
       "      <td>1215351</td>\n",
       "      <td>1.215230e+06</td>\n",
       "      <td>92445.7</td>\n",
       "      <td>2.58681</td>\n",
       "      <td>1261587</td>\n",
       "      <td>1215351</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>21845</td>\n",
       "      <td>21757.3</td>\n",
       "      <td>83.9692</td>\n",
       "      <td>9.8310</td>\n",
       "      <td>12</td>\n",
       "      <td>113</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>941</td>\n",
       "      <td>105409.0</td>\n",
       "      <td>2.49580</td>\n",
       "      <td>1401680</td>\n",
       "      <td>1378036</td>\n",
       "      <td>1.378411e+06</td>\n",
       "      <td>106024.0</td>\n",
       "      <td>2.48372</td>\n",
       "      <td>1401680</td>\n",
       "      <td>1378036</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>25933</td>\n",
       "      <td>25989.1</td>\n",
       "      <td>78.4338</td>\n",
       "      <td>9.6527</td>\n",
       "      <td>13</td>\n",
       "      <td>113</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>942</td>\n",
       "      <td>97845.9</td>\n",
       "      <td>2.71220</td>\n",
       "      <td>1348666</td>\n",
       "      <td>1327352</td>\n",
       "      <td>1.327838e+06</td>\n",
       "      <td>98188.8</td>\n",
       "      <td>2.67378</td>\n",
       "      <td>1348666</td>\n",
       "      <td>1327352</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>22480</td>\n",
       "      <td>22496.6</td>\n",
       "      <td>82.0008</td>\n",
       "      <td>11.0276</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>943</td>\n",
       "      <td>91645.5</td>\n",
       "      <td>2.54213</td>\n",
       "      <td>1199233</td>\n",
       "      <td>1151414</td>\n",
       "      <td>1.151577e+06</td>\n",
       "      <td>91794.2</td>\n",
       "      <td>2.55823</td>\n",
       "      <td>1199233</td>\n",
       "      <td>1151414</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>19118</td>\n",
       "      <td>19224.9</td>\n",
       "      <td>82.6553</td>\n",
       "      <td>10.2869</td>\n",
       "      <td>20</td>\n",
       "      <td>117</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>944</td>\n",
       "      <td>84635.4</td>\n",
       "      <td>2.70107</td>\n",
       "      <td>1178929</td>\n",
       "      <td>1166146</td>\n",
       "      <td>1.166051e+06</td>\n",
       "      <td>84755.6</td>\n",
       "      <td>2.69546</td>\n",
       "      <td>1178929</td>\n",
       "      <td>1166146</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>21528</td>\n",
       "      <td>21539.6</td>\n",
       "      <td>80.2398</td>\n",
       "      <td>8.7413</td>\n",
       "      <td>13</td>\n",
       "      <td>119</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>946</td>\n",
       "      <td>87852.2</td>\n",
       "      <td>2.61168</td>\n",
       "      <td>1117626</td>\n",
       "      <td>1103701</td>\n",
       "      <td>1.103847e+06</td>\n",
       "      <td>89134.1</td>\n",
       "      <td>2.54316</td>\n",
       "      <td>1117626</td>\n",
       "      <td>1103701</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>17863</td>\n",
       "      <td>17884.9</td>\n",
       "      <td>81.4798</td>\n",
       "      <td>9.4426</td>\n",
       "      <td>15</td>\n",
       "      <td>112</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>947</td>\n",
       "      <td>78332.6</td>\n",
       "      <td>2.57172</td>\n",
       "      <td>1073336</td>\n",
       "      <td>1059944</td>\n",
       "      <td>1.060117e+06</td>\n",
       "      <td>79455.9</td>\n",
       "      <td>2.54994</td>\n",
       "      <td>1073336</td>\n",
       "      <td>1059944</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>19466</td>\n",
       "      <td>19613.1</td>\n",
       "      <td>82.3695</td>\n",
       "      <td>10.1990</td>\n",
       "      <td>7</td>\n",
       "      <td>133</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>948</td>\n",
       "      <td>102922.0</td>\n",
       "      <td>2.61459</td>\n",
       "      <td>1385696</td>\n",
       "      <td>1365485</td>\n",
       "      <td>1.365236e+06</td>\n",
       "      <td>102094.0</td>\n",
       "      <td>2.63238</td>\n",
       "      <td>1385696</td>\n",
       "      <td>1365485</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>24206</td>\n",
       "      <td>24167.8</td>\n",
       "      <td>78.7637</td>\n",
       "      <td>8.8648</td>\n",
       "      <td>19</td>\n",
       "      <td>123</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>949</td>\n",
       "      <td>84782.9</td>\n",
       "      <td>2.54510</td>\n",
       "      <td>1146611</td>\n",
       "      <td>1127871</td>\n",
       "      <td>1.127618e+06</td>\n",
       "      <td>85004.7</td>\n",
       "      <td>2.51892</td>\n",
       "      <td>1146611</td>\n",
       "      <td>1127871</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>18614</td>\n",
       "      <td>18394.5</td>\n",
       "      <td>81.5268</td>\n",
       "      <td>9.8990</td>\n",
       "      <td>21</td>\n",
       "      <td>114</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>951</td>\n",
       "      <td>85246.9</td>\n",
       "      <td>2.54369</td>\n",
       "      <td>1174329</td>\n",
       "      <td>1143681</td>\n",
       "      <td>1.143581e+06</td>\n",
       "      <td>85217.8</td>\n",
       "      <td>2.57784</td>\n",
       "      <td>1174329</td>\n",
       "      <td>1143681</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>20301</td>\n",
       "      <td>20165.2</td>\n",
       "      <td>88.7372</td>\n",
       "      <td>10.4012</td>\n",
       "      <td>18</td>\n",
       "      <td>115</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>952</td>\n",
       "      <td>81134.3</td>\n",
       "      <td>2.67073</td>\n",
       "      <td>1076424</td>\n",
       "      <td>1065675</td>\n",
       "      <td>1.065845e+06</td>\n",
       "      <td>80898.0</td>\n",
       "      <td>2.67095</td>\n",
       "      <td>1076424</td>\n",
       "      <td>1065675</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>18535</td>\n",
       "      <td>18384.8</td>\n",
       "      <td>85.8218</td>\n",
       "      <td>10.3582</td>\n",
       "      <td>19</td>\n",
       "      <td>125</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>953</td>\n",
       "      <td>69624.3</td>\n",
       "      <td>2.67202</td>\n",
       "      <td>943769</td>\n",
       "      <td>926556</td>\n",
       "      <td>9.266063e+05</td>\n",
       "      <td>68606.7</td>\n",
       "      <td>2.67924</td>\n",
       "      <td>943769</td>\n",
       "      <td>926556</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>17493</td>\n",
       "      <td>17351.4</td>\n",
       "      <td>83.6060</td>\n",
       "      <td>9.3107</td>\n",
       "      <td>21</td>\n",
       "      <td>108</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>955</td>\n",
       "      <td>85837.8</td>\n",
       "      <td>2.46677</td>\n",
       "      <td>1123836</td>\n",
       "      <td>1113371</td>\n",
       "      <td>1.113464e+06</td>\n",
       "      <td>86832.9</td>\n",
       "      <td>2.45705</td>\n",
       "      <td>1123836</td>\n",
       "      <td>1113371</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>21056</td>\n",
       "      <td>20724.8</td>\n",
       "      <td>84.5846</td>\n",
       "      <td>9.7419</td>\n",
       "      <td>16</td>\n",
       "      <td>110</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>956</td>\n",
       "      <td>84561.6</td>\n",
       "      <td>2.49368</td>\n",
       "      <td>1090093</td>\n",
       "      <td>1081204</td>\n",
       "      <td>1.080985e+06</td>\n",
       "      <td>85156.1</td>\n",
       "      <td>2.52617</td>\n",
       "      <td>1090093</td>\n",
       "      <td>1081204</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>19662</td>\n",
       "      <td>19436.8</td>\n",
       "      <td>87.5603</td>\n",
       "      <td>10.1681</td>\n",
       "      <td>20</td>\n",
       "      <td>144</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>958</td>\n",
       "      <td>96083.1</td>\n",
       "      <td>2.56818</td>\n",
       "      <td>1312819</td>\n",
       "      <td>1288092</td>\n",
       "      <td>1.287782e+06</td>\n",
       "      <td>97541.0</td>\n",
       "      <td>2.53945</td>\n",
       "      <td>1312819</td>\n",
       "      <td>1288092</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>25664</td>\n",
       "      <td>25666.3</td>\n",
       "      <td>75.7356</td>\n",
       "      <td>8.9786</td>\n",
       "      <td>14</td>\n",
       "      <td>111</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>960</td>\n",
       "      <td>86840.7</td>\n",
       "      <td>2.75365</td>\n",
       "      <td>1271455</td>\n",
       "      <td>1253252</td>\n",
       "      <td>1.253178e+06</td>\n",
       "      <td>88408.9</td>\n",
       "      <td>2.69742</td>\n",
       "      <td>1271455</td>\n",
       "      <td>1253252</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>25633</td>\n",
       "      <td>25480.3</td>\n",
       "      <td>75.9531</td>\n",
       "      <td>8.8690</td>\n",
       "      <td>10</td>\n",
       "      <td>105</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>963</td>\n",
       "      <td>92990.0</td>\n",
       "      <td>2.68920</td>\n",
       "      <td>1295814</td>\n",
       "      <td>1257779</td>\n",
       "      <td>1.257753e+06</td>\n",
       "      <td>94222.6</td>\n",
       "      <td>2.66638</td>\n",
       "      <td>1295814</td>\n",
       "      <td>1257779</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>26980</td>\n",
       "      <td>27096.4</td>\n",
       "      <td>75.9289</td>\n",
       "      <td>9.9017</td>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>966</td>\n",
       "      <td>82372.3</td>\n",
       "      <td>2.49764</td>\n",
       "      <td>1068966</td>\n",
       "      <td>1035408</td>\n",
       "      <td>1.035604e+06</td>\n",
       "      <td>82642.1</td>\n",
       "      <td>2.47973</td>\n",
       "      <td>1068966</td>\n",
       "      <td>1035408</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>17656</td>\n",
       "      <td>17588.2</td>\n",
       "      <td>79.3642</td>\n",
       "      <td>9.6359</td>\n",
       "      <td>15</td>\n",
       "      <td>107</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>967</td>\n",
       "      <td>87072.7</td>\n",
       "      <td>2.55789</td>\n",
       "      <td>1213119</td>\n",
       "      <td>1196255</td>\n",
       "      <td>1.196099e+06</td>\n",
       "      <td>87682.9</td>\n",
       "      <td>2.52125</td>\n",
       "      <td>1213119</td>\n",
       "      <td>1196255</td>\n",
       "      <td>...</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>24819</td>\n",
       "      <td>24541.2</td>\n",
       "      <td>81.0572</td>\n",
       "      <td>9.3850</td>\n",
       "      <td>23</td>\n",
       "      <td>110</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>970</td>\n",
       "      <td>96319.4</td>\n",
       "      <td>2.65963</td>\n",
       "      <td>1342496</td>\n",
       "      <td>1319557</td>\n",
       "      <td>1.319510e+06</td>\n",
       "      <td>95951.9</td>\n",
       "      <td>2.61778</td>\n",
       "      <td>1342496</td>\n",
       "      <td>1319557</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>26387</td>\n",
       "      <td>26335.6</td>\n",
       "      <td>77.1904</td>\n",
       "      <td>8.7942</td>\n",
       "      <td>14</td>\n",
       "      <td>108</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>974</td>\n",
       "      <td>101604.0</td>\n",
       "      <td>2.43760</td>\n",
       "      <td>1249244</td>\n",
       "      <td>1228296</td>\n",
       "      <td>1.228448e+06</td>\n",
       "      <td>86685.3</td>\n",
       "      <td>2.45646</td>\n",
       "      <td>1249244</td>\n",
       "      <td>1228296</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>24054</td>\n",
       "      <td>24103.6</td>\n",
       "      <td>79.1514</td>\n",
       "      <td>9.9001</td>\n",
       "      <td>15</td>\n",
       "      <td>118</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>978</td>\n",
       "      <td>95052.0</td>\n",
       "      <td>2.57599</td>\n",
       "      <td>1283196</td>\n",
       "      <td>1258702</td>\n",
       "      <td>1.258371e+06</td>\n",
       "      <td>96268.4</td>\n",
       "      <td>2.57687</td>\n",
       "      <td>1283196</td>\n",
       "      <td>1258702</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>21762</td>\n",
       "      <td>21563.0</td>\n",
       "      <td>84.4026</td>\n",
       "      <td>9.1391</td>\n",
       "      <td>19</td>\n",
       "      <td>113</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>980</td>\n",
       "      <td>83573.5</td>\n",
       "      <td>2.63560</td>\n",
       "      <td>1156083</td>\n",
       "      <td>1142013</td>\n",
       "      <td>1.142498e+06</td>\n",
       "      <td>83657.7</td>\n",
       "      <td>2.65995</td>\n",
       "      <td>1156083</td>\n",
       "      <td>1142013</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>20635</td>\n",
       "      <td>20680.4</td>\n",
       "      <td>82.2521</td>\n",
       "      <td>9.3360</td>\n",
       "      <td>11</td>\n",
       "      <td>114</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>982</td>\n",
       "      <td>86467.5</td>\n",
       "      <td>2.54377</td>\n",
       "      <td>1167189</td>\n",
       "      <td>1150351</td>\n",
       "      <td>1.150225e+06</td>\n",
       "      <td>88255.2</td>\n",
       "      <td>2.59982</td>\n",
       "      <td>1167189</td>\n",
       "      <td>1150351</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>20519</td>\n",
       "      <td>20497.6</td>\n",
       "      <td>84.6226</td>\n",
       "      <td>10.0335</td>\n",
       "      <td>18</td>\n",
       "      <td>115</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>989</td>\n",
       "      <td>84454.7</td>\n",
       "      <td>2.70885</td>\n",
       "      <td>1179197</td>\n",
       "      <td>1159264</td>\n",
       "      <td>1.159285e+06</td>\n",
       "      <td>84898.0</td>\n",
       "      <td>2.66912</td>\n",
       "      <td>1179197</td>\n",
       "      <td>1159264</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>21607</td>\n",
       "      <td>21586.3</td>\n",
       "      <td>82.8139</td>\n",
       "      <td>11.2561</td>\n",
       "      <td>12</td>\n",
       "      <td>122</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>991</td>\n",
       "      <td>92153.1</td>\n",
       "      <td>2.51387</td>\n",
       "      <td>1266837</td>\n",
       "      <td>1238487</td>\n",
       "      <td>1.238382e+06</td>\n",
       "      <td>91833.0</td>\n",
       "      <td>2.54244</td>\n",
       "      <td>1266837</td>\n",
       "      <td>1238487</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>24065</td>\n",
       "      <td>23910.7</td>\n",
       "      <td>80.3109</td>\n",
       "      <td>9.6696</td>\n",
       "      <td>17</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>995</td>\n",
       "      <td>79617.6</td>\n",
       "      <td>2.56058</td>\n",
       "      <td>1042971</td>\n",
       "      <td>1036252</td>\n",
       "      <td>1.036423e+06</td>\n",
       "      <td>80652.1</td>\n",
       "      <td>2.54024</td>\n",
       "      <td>1042971</td>\n",
       "      <td>1036252</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>17646</td>\n",
       "      <td>17524.5</td>\n",
       "      <td>84.8926</td>\n",
       "      <td>9.0628</td>\n",
       "      <td>27</td>\n",
       "      <td>115</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>996</td>\n",
       "      <td>109013.0</td>\n",
       "      <td>2.61384</td>\n",
       "      <td>1413714</td>\n",
       "      <td>1394271</td>\n",
       "      <td>1.395218e+06</td>\n",
       "      <td>109230.0</td>\n",
       "      <td>2.61540</td>\n",
       "      <td>1413714</td>\n",
       "      <td>1394271</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>23272</td>\n",
       "      <td>23203.6</td>\n",
       "      <td>80.6713</td>\n",
       "      <td>9.7519</td>\n",
       "      <td>11</td>\n",
       "      <td>119</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>999</td>\n",
       "      <td>79325.0</td>\n",
       "      <td>2.73955</td>\n",
       "      <td>1135963</td>\n",
       "      <td>1118396</td>\n",
       "      <td>1.118191e+06</td>\n",
       "      <td>80113.4</td>\n",
       "      <td>2.70566</td>\n",
       "      <td>1135963</td>\n",
       "      <td>1118396</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>22994</td>\n",
       "      <td>22940.8</td>\n",
       "      <td>81.2468</td>\n",
       "      <td>10.0104</td>\n",
       "      <td>13</td>\n",
       "      <td>117</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>487 rows  637 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   L Cortex White Surface Total Area   L Cortex Mean Thickness  \\\n",
       "0       0                             91559.1                   2.66137   \n",
       "1      10                             87801.8                   2.59872   \n",
       "2    1000                             84704.4                   2.63064   \n",
       "3    1001                            100968.0                   2.63486   \n",
       "4     103                             79255.4                   2.67144   \n",
       "5      12                             79338.6                   2.56434   \n",
       "6     128                             78525.1                   2.68181   \n",
       "7      13                             87890.2                   2.59890   \n",
       "9     131                             94714.7                   2.54105   \n",
       "10    132                             98049.4                   2.65850   \n",
       "11    133                            103685.0                   2.57657   \n",
       "12    134                             85282.2                   2.68347   \n",
       "13    135                             93135.4                   2.66900   \n",
       "14    136                             85523.8                   2.75854   \n",
       "15    138                             95111.7                   2.65536   \n",
       "16    139                             75033.5                   2.52904   \n",
       "17    140                            103796.0                   2.60240   \n",
       "18    141                             80641.1                   2.55906   \n",
       "19    142                             94488.5                   2.63243   \n",
       "20    143                             83619.1                   2.62288   \n",
       "21    145                             83386.2                   2.52836   \n",
       "22    146                             84920.7                   2.55846   \n",
       "23    147                             94609.5                   2.58726   \n",
       "24    148                             79669.2                   2.55312   \n",
       "25    149                             93475.0                   2.54315   \n",
       "26     15                             81820.6                   2.58990   \n",
       "27    150                             81003.9                   2.56500   \n",
       "28    151                             85433.2                   2.66207   \n",
       "29    152                             90496.6                   2.65899   \n",
       "30    153                             88420.0                   2.54916   \n",
       "..    ...                                 ...                       ...   \n",
       "471   939                             86099.0                   2.52789   \n",
       "472   940                             93159.3                   2.61385   \n",
       "473   941                            105409.0                   2.49580   \n",
       "474   942                             97845.9                   2.71220   \n",
       "475   943                             91645.5                   2.54213   \n",
       "476   944                             84635.4                   2.70107   \n",
       "477   946                             87852.2                   2.61168   \n",
       "478   947                             78332.6                   2.57172   \n",
       "479   948                            102922.0                   2.61459   \n",
       "480   949                             84782.9                   2.54510   \n",
       "481   951                             85246.9                   2.54369   \n",
       "482   952                             81134.3                   2.67073   \n",
       "483   953                             69624.3                   2.67202   \n",
       "484   955                             85837.8                   2.46677   \n",
       "485   956                             84561.6                   2.49368   \n",
       "486   958                             96083.1                   2.56818   \n",
       "487   960                             86840.7                   2.75365   \n",
       "488   963                             92990.0                   2.68920   \n",
       "489   966                             82372.3                   2.49764   \n",
       "490   967                             87072.7                   2.55789   \n",
       "491   970                             96319.4                   2.65963   \n",
       "492   974                            101604.0                   2.43760   \n",
       "493   978                             95052.0                   2.57599   \n",
       "494   980                             83573.5                   2.63560   \n",
       "495   982                             86467.5                   2.54377   \n",
       "496   989                             84454.7                   2.70885   \n",
       "497   991                             92153.1                   2.51387   \n",
       "498   995                             79617.6                   2.56058   \n",
       "499   996                            109013.0                   2.61384   \n",
       "500   999                             79325.0                   2.73955   \n",
       "\n",
       "      L Brain Segmentation Volume  \\\n",
       "0                         1266925   \n",
       "1                         1191311   \n",
       "2                         1129977   \n",
       "3                         1362391   \n",
       "4                         1059360   \n",
       "5                         1176364   \n",
       "6                         1071264   \n",
       "7                         1140328   \n",
       "9                         1247199   \n",
       "10                        1409536   \n",
       "11                        1398236   \n",
       "12                        1165461   \n",
       "13                        1271889   \n",
       "14                        1197918   \n",
       "15                        1312880   \n",
       "16                        1019349   \n",
       "17                        1363925   \n",
       "18                        1102551   \n",
       "19                        1257434   \n",
       "20                        1091656   \n",
       "21                        1111972   \n",
       "22                        1209213   \n",
       "23                        1260721   \n",
       "24                        1084902   \n",
       "25                        1255548   \n",
       "26                        1118911   \n",
       "27                        1114273   \n",
       "28                        1178838   \n",
       "29                        1192808   \n",
       "30                        1211413   \n",
       "..                            ...   \n",
       "471                       1151328   \n",
       "472                       1261587   \n",
       "473                       1401680   \n",
       "474                       1348666   \n",
       "475                       1199233   \n",
       "476                       1178929   \n",
       "477                       1117626   \n",
       "478                       1073336   \n",
       "479                       1385696   \n",
       "480                       1146611   \n",
       "481                       1174329   \n",
       "482                       1076424   \n",
       "483                        943769   \n",
       "484                       1123836   \n",
       "485                       1090093   \n",
       "486                       1312819   \n",
       "487                       1271455   \n",
       "488                       1295814   \n",
       "489                       1068966   \n",
       "490                       1213119   \n",
       "491                       1342496   \n",
       "492                       1249244   \n",
       "493                       1283196   \n",
       "494                       1156083   \n",
       "495                       1167189   \n",
       "496                       1179197   \n",
       "497                       1266837   \n",
       "498                       1042971   \n",
       "499                       1413714   \n",
       "500                       1135963   \n",
       "\n",
       "      L Brain Segmentation Volume Without Ventricles  \\\n",
       "0                                            1248772   \n",
       "1                                            1177870   \n",
       "2                                            1116423   \n",
       "3                                            1345462   \n",
       "4                                            1046824   \n",
       "5                                            1161059   \n",
       "6                                            1054853   \n",
       "7                                            1129039   \n",
       "9                                            1229357   \n",
       "10                                           1339095   \n",
       "11                                           1378903   \n",
       "12                                           1146992   \n",
       "13                                           1251653   \n",
       "14                                           1188653   \n",
       "15                                           1295654   \n",
       "16                                           1012515   \n",
       "17                                           1340839   \n",
       "18                                           1082833   \n",
       "19                                           1244847   \n",
       "20                                           1068422   \n",
       "21                                           1094242   \n",
       "22                                           1180240   \n",
       "23                                           1244787   \n",
       "24                                           1061281   \n",
       "25                                           1240815   \n",
       "26                                           1102769   \n",
       "27                                           1104168   \n",
       "28                                           1165048   \n",
       "29                                           1176554   \n",
       "30                                           1198000   \n",
       "..                                               ...   \n",
       "471                                          1137121   \n",
       "472                                          1215351   \n",
       "473                                          1378036   \n",
       "474                                          1327352   \n",
       "475                                          1151414   \n",
       "476                                          1166146   \n",
       "477                                          1103701   \n",
       "478                                          1059944   \n",
       "479                                          1365485   \n",
       "480                                          1127871   \n",
       "481                                          1143681   \n",
       "482                                          1065675   \n",
       "483                                           926556   \n",
       "484                                          1113371   \n",
       "485                                          1081204   \n",
       "486                                          1288092   \n",
       "487                                          1253252   \n",
       "488                                          1257779   \n",
       "489                                          1035408   \n",
       "490                                          1196255   \n",
       "491                                          1319557   \n",
       "492                                          1228296   \n",
       "493                                          1258702   \n",
       "494                                          1142013   \n",
       "495                                          1150351   \n",
       "496                                          1159264   \n",
       "497                                          1238487   \n",
       "498                                          1036252   \n",
       "499                                          1394271   \n",
       "500                                          1118396   \n",
       "\n",
       "     L  Brain Segmentation Volume Without Ventricles from Surf  \\\n",
       "0                                         1.248798e+06           \n",
       "1                                         1.177810e+06           \n",
       "2                                         1.116157e+06           \n",
       "3                                         1.345388e+06           \n",
       "4                                         1.046769e+06           \n",
       "5                                         1.160913e+06           \n",
       "6                                         1.055068e+06           \n",
       "7                                         1.129032e+06           \n",
       "9                                         1.229742e+06           \n",
       "10                                        1.338803e+06           \n",
       "11                                        1.379042e+06           \n",
       "12                                        1.146684e+06           \n",
       "13                                        1.251647e+06           \n",
       "14                                        1.188462e+06           \n",
       "15                                        1.295472e+06           \n",
       "16                                        1.012630e+06           \n",
       "17                                        1.341556e+06           \n",
       "18                                        1.082708e+06           \n",
       "19                                        1.245186e+06           \n",
       "20                                        1.068585e+06           \n",
       "21                                        1.093683e+06           \n",
       "22                                        1.180156e+06           \n",
       "23                                        1.244942e+06           \n",
       "24                                        1.061293e+06           \n",
       "25                                        1.240710e+06           \n",
       "26                                        1.102539e+06           \n",
       "27                                        1.104022e+06           \n",
       "28                                        1.164786e+06           \n",
       "29                                        1.175949e+06           \n",
       "30                                        1.198011e+06           \n",
       "..                                                 ...           \n",
       "471                                       1.136990e+06           \n",
       "472                                       1.215230e+06           \n",
       "473                                       1.378411e+06           \n",
       "474                                       1.327838e+06           \n",
       "475                                       1.151577e+06           \n",
       "476                                       1.166051e+06           \n",
       "477                                       1.103847e+06           \n",
       "478                                       1.060117e+06           \n",
       "479                                       1.365236e+06           \n",
       "480                                       1.127618e+06           \n",
       "481                                       1.143581e+06           \n",
       "482                                       1.065845e+06           \n",
       "483                                       9.266063e+05           \n",
       "484                                       1.113464e+06           \n",
       "485                                       1.080985e+06           \n",
       "486                                       1.287782e+06           \n",
       "487                                       1.253178e+06           \n",
       "488                                       1.257753e+06           \n",
       "489                                       1.035604e+06           \n",
       "490                                       1.196099e+06           \n",
       "491                                       1.319510e+06           \n",
       "492                                       1.228448e+06           \n",
       "493                                       1.258371e+06           \n",
       "494                                       1.142498e+06           \n",
       "495                                       1.150225e+06           \n",
       "496                                       1.159285e+06           \n",
       "497                                       1.238382e+06           \n",
       "498                                       1.036423e+06           \n",
       "499                                       1.395218e+06           \n",
       "500                                       1.118191e+06           \n",
       "\n",
       "      R Cortex White Surface Total Area   R Cortex Mean Thickness  \\\n",
       "0                               92652.3                   2.67640   \n",
       "1                               87335.4                   2.62856   \n",
       "2                               85373.0                   2.62956   \n",
       "3                              101887.0                   2.59180   \n",
       "4                               78432.2                   2.66245   \n",
       "5                               80724.6                   2.57059   \n",
       "6                               78855.4                   2.66719   \n",
       "7                               87944.7                   2.61157   \n",
       "9                               95115.3                   2.51661   \n",
       "10                              99493.8                   2.65336   \n",
       "11                             102384.0                   2.58776   \n",
       "12                              87742.9                   2.61131   \n",
       "13                              93052.1                   2.67368   \n",
       "14                              83964.4                   2.78450   \n",
       "15                              95071.0                   2.61290   \n",
       "16                              74049.8                   2.53346   \n",
       "17                             104259.0                   2.57490   \n",
       "18                              80701.8                   2.56191   \n",
       "19                              94124.9                   2.58778   \n",
       "20                              82517.5                   2.59367   \n",
       "21                              82724.4                   2.54718   \n",
       "22                              86456.5                   2.56250   \n",
       "23                              94792.2                   2.61917   \n",
       "24                              80421.2                   2.50960   \n",
       "25                              95572.9                   2.50041   \n",
       "26                              82296.2                   2.56846   \n",
       "27                              80895.5                   2.55624   \n",
       "28                              86921.9                   2.63077   \n",
       "29                              90155.1                   2.69232   \n",
       "30                              89815.2                   2.55794   \n",
       "..                                  ...                       ...   \n",
       "471                             88603.4                   2.48837   \n",
       "472                             92445.7                   2.58681   \n",
       "473                            106024.0                   2.48372   \n",
       "474                             98188.8                   2.67378   \n",
       "475                             91794.2                   2.55823   \n",
       "476                             84755.6                   2.69546   \n",
       "477                             89134.1                   2.54316   \n",
       "478                             79455.9                   2.54994   \n",
       "479                            102094.0                   2.63238   \n",
       "480                             85004.7                   2.51892   \n",
       "481                             85217.8                   2.57784   \n",
       "482                             80898.0                   2.67095   \n",
       "483                             68606.7                   2.67924   \n",
       "484                             86832.9                   2.45705   \n",
       "485                             85156.1                   2.52617   \n",
       "486                             97541.0                   2.53945   \n",
       "487                             88408.9                   2.69742   \n",
       "488                             94222.6                   2.66638   \n",
       "489                             82642.1                   2.47973   \n",
       "490                             87682.9                   2.52125   \n",
       "491                             95951.9                   2.61778   \n",
       "492                             86685.3                   2.45646   \n",
       "493                             96268.4                   2.57687   \n",
       "494                             83657.7                   2.65995   \n",
       "495                             88255.2                   2.59982   \n",
       "496                             84898.0                   2.66912   \n",
       "497                             91833.0                   2.54244   \n",
       "498                             80652.1                   2.54024   \n",
       "499                            109230.0                   2.61540   \n",
       "500                             80113.4                   2.70566   \n",
       "\n",
       "     R  Brain Segmentation Volume  \\\n",
       "0                         1266925   \n",
       "1                         1191311   \n",
       "2                         1129977   \n",
       "3                         1362391   \n",
       "4                         1059360   \n",
       "5                         1176364   \n",
       "6                         1071264   \n",
       "7                         1140328   \n",
       "9                         1247199   \n",
       "10                        1409536   \n",
       "11                        1398236   \n",
       "12                        1165461   \n",
       "13                        1271889   \n",
       "14                        1197918   \n",
       "15                        1312880   \n",
       "16                        1019349   \n",
       "17                        1363925   \n",
       "18                        1102551   \n",
       "19                        1257434   \n",
       "20                        1091656   \n",
       "21                        1111972   \n",
       "22                        1209213   \n",
       "23                        1260721   \n",
       "24                        1084902   \n",
       "25                        1255548   \n",
       "26                        1118911   \n",
       "27                        1114273   \n",
       "28                        1178838   \n",
       "29                        1192808   \n",
       "30                        1211413   \n",
       "..                            ...   \n",
       "471                       1151328   \n",
       "472                       1261587   \n",
       "473                       1401680   \n",
       "474                       1348666   \n",
       "475                       1199233   \n",
       "476                       1178929   \n",
       "477                       1117626   \n",
       "478                       1073336   \n",
       "479                       1385696   \n",
       "480                       1146611   \n",
       "481                       1174329   \n",
       "482                       1076424   \n",
       "483                        943769   \n",
       "484                       1123836   \n",
       "485                       1090093   \n",
       "486                       1312819   \n",
       "487                       1271455   \n",
       "488                       1295814   \n",
       "489                       1068966   \n",
       "490                       1213119   \n",
       "491                       1342496   \n",
       "492                       1249244   \n",
       "493                       1283196   \n",
       "494                       1156083   \n",
       "495                       1167189   \n",
       "496                       1179197   \n",
       "497                       1266837   \n",
       "498                       1042971   \n",
       "499                       1413714   \n",
       "500                       1135963   \n",
       "\n",
       "     R Brain Segmentation Volume Without Ventricles     ...      normRange3  \\\n",
       "0                                           1248772     ...              78   \n",
       "1                                           1177870     ...              78   \n",
       "2                                           1116423     ...              69   \n",
       "3                                           1345462     ...              76   \n",
       "4                                           1046824     ...              64   \n",
       "5                                           1161059     ...              82   \n",
       "6                                           1054853     ...              67   \n",
       "7                                           1129039     ...              90   \n",
       "9                                           1229357     ...              92   \n",
       "10                                          1339095     ...              75   \n",
       "11                                          1378903     ...              93   \n",
       "12                                          1146992     ...             101   \n",
       "13                                          1251653     ...              89   \n",
       "14                                          1188653     ...              73   \n",
       "15                                          1295654     ...              80   \n",
       "16                                          1012515     ...              75   \n",
       "17                                          1340839     ...             104   \n",
       "18                                          1082833     ...              95   \n",
       "19                                          1244847     ...              92   \n",
       "20                                          1068422     ...             104   \n",
       "21                                          1094242     ...              58   \n",
       "22                                          1180240     ...             101   \n",
       "23                                          1244787     ...              84   \n",
       "24                                          1061281     ...              79   \n",
       "25                                          1240815     ...              85   \n",
       "26                                          1102769     ...              84   \n",
       "27                                          1104168     ...              68   \n",
       "28                                          1165048     ...              86   \n",
       "29                                          1176554     ...              73   \n",
       "30                                          1198000     ...              56   \n",
       "..                                              ...     ...             ...   \n",
       "471                                         1137121     ...              95   \n",
       "472                                         1215351     ...             102   \n",
       "473                                         1378036     ...              97   \n",
       "474                                         1327352     ...              93   \n",
       "475                                         1151414     ...             104   \n",
       "476                                         1166146     ...              86   \n",
       "477                                         1103701     ...              87   \n",
       "478                                         1059944     ...              82   \n",
       "479                                         1365485     ...              73   \n",
       "480                                         1127871     ...              73   \n",
       "481                                         1143681     ...              98   \n",
       "482                                         1065675     ...              71   \n",
       "483                                          926556     ...              66   \n",
       "484                                         1113371     ...              73   \n",
       "485                                         1081204     ...              87   \n",
       "486                                         1288092     ...              74   \n",
       "487                                         1253252     ...              99   \n",
       "488                                         1257779     ...              83   \n",
       "489                                         1035408     ...              90   \n",
       "490                                         1196255     ...              71   \n",
       "491                                         1319557     ...              97   \n",
       "492                                         1228296     ...              85   \n",
       "493                                         1258702     ...              74   \n",
       "494                                         1142013     ...              83   \n",
       "495                                         1150351     ...              92   \n",
       "496                                         1159264     ...             118   \n",
       "497                                         1238487     ...              93   \n",
       "498                                         1036252     ...              72   \n",
       "499                                         1394271     ...              98   \n",
       "500                                         1118396     ...              94   \n",
       "\n",
       "     BrainStem_index  BrainStem_SegId  BrainStem_Nvoxels  \\\n",
       "0                 11               16              22857   \n",
       "1                 11               16              18257   \n",
       "2                 11               16              19200   \n",
       "3                 11               16              21958   \n",
       "4                 11               16              18079   \n",
       "5                 11               16              22930   \n",
       "6                 11               16              17410   \n",
       "7                 11               16              18974   \n",
       "9                 11               16              24174   \n",
       "10                11               16              23817   \n",
       "11                11               16              25079   \n",
       "12                11               16              20944   \n",
       "13                11               16              21204   \n",
       "14                11               16              24582   \n",
       "15                11               16              26103   \n",
       "16                11               16              20369   \n",
       "17                11               16              23794   \n",
       "18                11               16              20636   \n",
       "19                11               16              22795   \n",
       "20                11               16              18719   \n",
       "21                11               16              19803   \n",
       "22                11               16              20122   \n",
       "23                11               16              21757   \n",
       "24                11               16              18759   \n",
       "25                11               16              20518   \n",
       "26                11               16              19331   \n",
       "27                11               16              22105   \n",
       "28                11               16              19878   \n",
       "29                11               16              19866   \n",
       "30                11               16              23252   \n",
       "..               ...              ...                ...   \n",
       "471               11               16              21112   \n",
       "472               11               16              21845   \n",
       "473               11               16              25933   \n",
       "474               11               16              22480   \n",
       "475               11               16              19118   \n",
       "476               11               16              21528   \n",
       "477               11               16              17863   \n",
       "478               11               16              19466   \n",
       "479               11               16              24206   \n",
       "480               11               16              18614   \n",
       "481               11               16              20301   \n",
       "482               11               16              18535   \n",
       "483               11               16              17493   \n",
       "484               11               16              21056   \n",
       "485               11               16              19662   \n",
       "486               11               16              25664   \n",
       "487               11               16              25633   \n",
       "488               11               16              26980   \n",
       "489               11               16              17656   \n",
       "490               11               16              24819   \n",
       "491               11               16              26387   \n",
       "492               11               16              24054   \n",
       "493               11               16              21762   \n",
       "494               11               16              20635   \n",
       "495               11               16              20519   \n",
       "496               11               16              21607   \n",
       "497               11               16              24065   \n",
       "498               11               16              17646   \n",
       "499               11               16              23272   \n",
       "500               11               16              22994   \n",
       "\n",
       "     BrainStem_volume_mm3  normMean4  normStdDev3  normMin3  normMax3  \\\n",
       "0                 22904.9    77.7730       9.7718        13       113   \n",
       "1                 18139.2    82.3428       9.6367        19       113   \n",
       "2                 19226.5    82.9126       9.6400        18       111   \n",
       "3                 21924.0    82.6825       9.1148        21       115   \n",
       "4                 17879.4    80.9856       9.8699        21       112   \n",
       "5                 22734.0    84.5854       9.2122        20       118   \n",
       "6                 17277.2    85.8374       9.7606        24       118   \n",
       "7                 18929.3    82.2677       9.9673         5       121   \n",
       "9                 24133.4    80.6521       9.4648        17       111   \n",
       "10                23681.6    79.6083      10.1321        14       116   \n",
       "11                24981.5    77.2783       8.9300        12       110   \n",
       "12                20973.5    77.2457       9.1203        17       104   \n",
       "13                21122.4    85.6754      10.1301        31       115   \n",
       "14                24544.6    79.4582       9.0830        20       133   \n",
       "15                25818.9    80.1656       9.1385        15       123   \n",
       "16                20192.8    84.6042       9.5492        22       110   \n",
       "17                23929.5    76.7749       9.6350         5       127   \n",
       "18                20730.0    83.4055      10.6106        20       120   \n",
       "19                22807.3    77.3085       9.0503        20       109   \n",
       "20                18765.1    81.1326       9.9091        12       133   \n",
       "21                19577.4    86.4223       9.6733        22       131   \n",
       "22                19987.5    81.9762       9.9796        12       127   \n",
       "23                21616.2    76.4430       8.8578        14       111   \n",
       "24                18643.5    87.1677       9.4922        23       119   \n",
       "25                20418.3    80.0462       9.0043        17       127   \n",
       "26                19394.6    81.9146       9.9756        10       119   \n",
       "27                21936.8    80.2958       8.6282        18       108   \n",
       "28                19861.2    84.2946       9.3110        22       123   \n",
       "29                19772.3    82.1009       9.6893        12       118   \n",
       "30                23064.6    83.8896       9.1852        32       122   \n",
       "..                    ...        ...          ...       ...       ...   \n",
       "471               21139.4    80.8985      10.0290        13       122   \n",
       "472               21757.3    83.9692       9.8310        12       113   \n",
       "473               25989.1    78.4338       9.6527        13       113   \n",
       "474               22496.6    82.0008      11.0276        10       120   \n",
       "475               19224.9    82.6553      10.2869        20       117   \n",
       "476               21539.6    80.2398       8.7413        13       119   \n",
       "477               17884.9    81.4798       9.4426        15       112   \n",
       "478               19613.1    82.3695      10.1990         7       133   \n",
       "479               24167.8    78.7637       8.8648        19       123   \n",
       "480               18394.5    81.5268       9.8990        21       114   \n",
       "481               20165.2    88.7372      10.4012        18       115   \n",
       "482               18384.8    85.8218      10.3582        19       125   \n",
       "483               17351.4    83.6060       9.3107        21       108   \n",
       "484               20724.8    84.5846       9.7419        16       110   \n",
       "485               19436.8    87.5603      10.1681        20       144   \n",
       "486               25666.3    75.7356       8.9786        14       111   \n",
       "487               25480.3    75.9531       8.8690        10       105   \n",
       "488               27096.4    75.9289       9.9017         5       116   \n",
       "489               17588.2    79.3642       9.6359        15       107   \n",
       "490               24541.2    81.0572       9.3850        23       110   \n",
       "491               26335.6    77.1904       8.7942        14       108   \n",
       "492               24103.6    79.1514       9.9001        15       118   \n",
       "493               21563.0    84.4026       9.1391        19       113   \n",
       "494               20680.4    82.2521       9.3360        11       114   \n",
       "495               20497.6    84.6226      10.0335        18       115   \n",
       "496               21586.3    82.8139      11.2561        12       122   \n",
       "497               23910.7    80.3109       9.6696        17       117   \n",
       "498               17524.5    84.8926       9.0628        27       115   \n",
       "499               23203.6    80.6713       9.7519        11       119   \n",
       "500               22940.8    81.2468      10.0104        13       117   \n",
       "\n",
       "     normRange2  \n",
       "0           100  \n",
       "1            94  \n",
       "2            93  \n",
       "3            94  \n",
       "4            91  \n",
       "5            98  \n",
       "6            94  \n",
       "7           116  \n",
       "9            94  \n",
       "10          102  \n",
       "11           98  \n",
       "12           87  \n",
       "13           84  \n",
       "14          113  \n",
       "15          108  \n",
       "16           88  \n",
       "17          122  \n",
       "18          100  \n",
       "19           89  \n",
       "20          121  \n",
       "21          109  \n",
       "22          115  \n",
       "23           97  \n",
       "24           96  \n",
       "25          110  \n",
       "26          109  \n",
       "27           90  \n",
       "28          101  \n",
       "29          106  \n",
       "30           90  \n",
       "..          ...  \n",
       "471         109  \n",
       "472         101  \n",
       "473         100  \n",
       "474         110  \n",
       "475          97  \n",
       "476         106  \n",
       "477          97  \n",
       "478         126  \n",
       "479         104  \n",
       "480          93  \n",
       "481          97  \n",
       "482         106  \n",
       "483          87  \n",
       "484          94  \n",
       "485         124  \n",
       "486          97  \n",
       "487          95  \n",
       "488         111  \n",
       "489          92  \n",
       "490          87  \n",
       "491          94  \n",
       "492         103  \n",
       "493          94  \n",
       "494         103  \n",
       "495          97  \n",
       "496         110  \n",
       "497         100  \n",
       "498          88  \n",
       "499         108  \n",
       "500         104  \n",
       "\n",
       "[487 rows x 637 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 637)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " ' L Cortex White Surface Total Area',\n",
       " ' L Cortex Mean Thickness',\n",
       " ' L Brain Segmentation Volume',\n",
       " ' L Brain Segmentation Volume Without Ventricles',\n",
       " 'L  Brain Segmentation Volume Without Ventricles from Surf',\n",
       " ' R Cortex White Surface Total Area',\n",
       " ' R Cortex Mean Thickness',\n",
       " 'R  Brain Segmentation Volume',\n",
       " 'R Brain Segmentation Volume Without Ventricles',\n",
       " ' R Brain Segmentation Volume Without Ventricles from Surf',\n",
       " 'l_caudalanteriorcingulate_SurfArea',\n",
       " 'l_caudalanteriorcingulate_GrayVol',\n",
       " 'l_caudalanteriorcingulate_ThickAvg',\n",
       " 'l_caudalanteriorcingulate_ThickStd',\n",
       " 'l_caudalanteriorcingulate_MeanCurv',\n",
       " 'l_caudalmiddlefrontal_SurfArea',\n",
       " 'l_caudalmiddlefrontal_GrayVol',\n",
       " 'l_caudalmiddlefrontal_ThickAvg',\n",
       " 'l_caudalmiddlefrontal_ThickStd',\n",
       " 'l_caudalmiddlefrontal_MeanCurv',\n",
       " 'l_cuneus_SurfArea',\n",
       " 'l_cuneus_GrayVol',\n",
       " 'l_cuneus_ThickAvg',\n",
       " 'l_cuneus_ThickStd',\n",
       " 'l_cuneus_MeanCurv',\n",
       " 'l_entorhinal_SurfArea',\n",
       " 'l_entorhinal_GrayVol',\n",
       " 'l_entorhinal_ThickAvg',\n",
       " 'l_entorhinal_ThickStd',\n",
       " 'l_entorhinal_MeanCurv',\n",
       " 'l_fusiform_SurfArea',\n",
       " 'l_fusiform_GrayVol',\n",
       " 'l_fusiform_ThickAvg',\n",
       " 'l_fusiform_ThickStd',\n",
       " 'l_fusiform_MeanCurv',\n",
       " 'l_inferiorparietal_SurfArea',\n",
       " 'l_inferiorparietal_GrayVol',\n",
       " 'l_inferiorparietal_ThickAvg',\n",
       " 'l_inferiorparietal_ThickStd',\n",
       " 'l_inferiorparietal_MeanCurv',\n",
       " 'l_inferiortemporal_SurfArea',\n",
       " 'l_inferiortemporal_GrayVol',\n",
       " 'l_inferiortemporal_ThickAvg',\n",
       " 'l_inferiortemporal_ThickStd',\n",
       " 'l_inferiortemporal_MeanCurv',\n",
       " 'l_isthmuscingulate_SurfArea',\n",
       " 'l_isthmuscingulate_GrayVol',\n",
       " 'l_isthmuscingulate_ThickAvg',\n",
       " 'l_isthmuscingulate_ThickStd',\n",
       " 'l_isthmuscingulate_MeanCurv',\n",
       " 'l_lateraloccipital_SurfArea',\n",
       " 'l_lateraloccipital_GrayVol',\n",
       " 'l_lateraloccipital_ThickAvg',\n",
       " 'l_lateraloccipital_ThickStd',\n",
       " 'l_lateraloccipital_MeanCurv',\n",
       " 'l_lateralorbitofrontal_SurfArea',\n",
       " 'l_lateralorbitofrontal_GrayVol',\n",
       " 'l_lateralorbitofrontal_ThickAvg',\n",
       " 'l_lateralorbitofrontal_ThickStd',\n",
       " 'l_lateralorbitofrontal_MeanCurv',\n",
       " 'l_lingual_SurfArea',\n",
       " 'l_lingual_GrayVol',\n",
       " 'l_lingual_ThickAvg',\n",
       " 'l_lingual_ThickStd',\n",
       " 'l_lingual_MeanCurv',\n",
       " 'l_medialorbitofrontal_SurfArea',\n",
       " 'l_medialorbitofrontal_GrayVol',\n",
       " 'l_medialorbitofrontal_ThickAvg',\n",
       " 'l_medialorbitofrontal_ThickStd',\n",
       " 'l_medialorbitofrontal_MeanCurv',\n",
       " 'l_middletemporal_SurfArea',\n",
       " 'l_middletemporal_GrayVol',\n",
       " 'l_middletemporal_ThickAvg',\n",
       " 'l_middletemporal_ThickStd',\n",
       " 'l_middletemporal_MeanCurv',\n",
       " 'l_parahippocampal_SurfArea',\n",
       " 'l_parahippocampal_GrayVol',\n",
       " 'l_parahippocampal_ThickAvg',\n",
       " 'l_parahippocampal_ThickStd',\n",
       " 'l_parahippocampal_MeanCurv',\n",
       " 'l_paracentral_SurfArea',\n",
       " 'l_paracentral_GrayVol',\n",
       " 'l_paracentral_ThickAvg',\n",
       " 'l_paracentral_ThickStd',\n",
       " 'l_paracentral_MeanCurv',\n",
       " 'l_parsopercularis_SurfArea',\n",
       " 'l_parsopercularis_GrayVol',\n",
       " 'l_parsopercularis_ThickAvg',\n",
       " 'l_parsopercularis_ThickStd',\n",
       " 'l_parsopercularis_MeanCurv',\n",
       " 'l_parsorbitalis_SurfArea',\n",
       " 'l_parsorbitalis_GrayVol',\n",
       " 'l_parsorbitalis_ThickAvg',\n",
       " 'l_parsorbitalis_ThickStd',\n",
       " 'l_parsorbitalis_MeanCurv',\n",
       " 'l_parstriangularis_SurfArea',\n",
       " 'l_parstriangularis_GrayVol',\n",
       " 'l_parstriangularis_ThickAvg',\n",
       " 'l_parstriangularis_ThickStd',\n",
       " 'l_parstriangularis_MeanCurv',\n",
       " 'l_pericalcarine_SurfArea',\n",
       " 'l_pericalcarine_GrayVol',\n",
       " 'l_pericalcarine_ThickAvg',\n",
       " 'l_pericalcarine_ThickStd',\n",
       " 'l_pericalcarine_MeanCurv',\n",
       " 'l_postcentral_SurfArea',\n",
       " 'l_postcentral_GrayVol',\n",
       " 'l_postcentral_ThickAvg',\n",
       " 'l_postcentral_ThickStd',\n",
       " 'l_postcentral_MeanCurv',\n",
       " 'l_posteriorcingulate_SurfArea',\n",
       " 'l_posteriorcingulate_GrayVol',\n",
       " 'l_posteriorcingulate_ThickAvg',\n",
       " 'l_posteriorcingulate_ThickStd',\n",
       " 'l_posteriorcingulate_MeanCurv',\n",
       " 'l_precentral_SurfArea',\n",
       " 'l_precentral_GrayVol',\n",
       " 'l_precentral_ThickAvg',\n",
       " 'l_precentral_ThickStd',\n",
       " 'l_precentral_MeanCurv',\n",
       " 'l_precuneus_SurfArea',\n",
       " 'l_precuneus_GrayVol',\n",
       " 'l_precuneus_ThickAvg',\n",
       " 'l_precuneus_ThickStd',\n",
       " 'l_precuneus_MeanCurv',\n",
       " 'l_rostralanteriorcingulate_SurfArea',\n",
       " 'l_rostralanteriorcingulate_GrayVol',\n",
       " 'l_rostralanteriorcingulate_ThickAvg',\n",
       " 'l_rostralanteriorcingulate_ThickStd',\n",
       " 'l_rostralanteriorcingulate_MeanCurv',\n",
       " 'l_rostralmiddlefrontal_SurfArea',\n",
       " 'l_rostralmiddlefrontal_GrayVol',\n",
       " 'l_rostralmiddlefrontal_ThickAvg',\n",
       " 'l_rostralmiddlefrontal_ThickStd',\n",
       " 'l_rostralmiddlefrontal_MeanCurv',\n",
       " 'l_superiorfrontal_SurfArea',\n",
       " 'l_superiorfrontal_GrayVol',\n",
       " 'l_superiorfrontal_ThickAvg',\n",
       " 'l_superiorfrontal_ThickStd',\n",
       " 'l_superiorfrontal_MeanCurv',\n",
       " 'l_superiorparietal_SurfArea',\n",
       " 'l_superiorparietal_GrayVol',\n",
       " 'l_superiorparietal_ThickAvg',\n",
       " 'l_superiorparietal_ThickStd',\n",
       " 'l_superiorparietal_MeanCurv',\n",
       " 'l_superiortemporal_SurfArea',\n",
       " 'l_superiortemporal_GrayVol',\n",
       " 'l_superiortemporal_ThickAvg',\n",
       " 'l_superiortemporal_ThickStd',\n",
       " 'l_superiortemporal_MeanCurv',\n",
       " 'l_supramarginal_SurfArea',\n",
       " 'l_supramarginal_GrayVol',\n",
       " 'l_supramarginal_ThickAvg',\n",
       " 'l_supramarginal_ThickStd',\n",
       " 'l_supramarginal_MeanCurv',\n",
       " 'l_transversetemporal_SurfArea',\n",
       " 'l_transversetemporal_GrayVol',\n",
       " 'l_transversetemporal_ThickAvg',\n",
       " 'l_transversetemporal_ThickStd',\n",
       " 'l_transversetemporal_MeanCurv',\n",
       " 'l_insula_SurfArea',\n",
       " 'l_insula_GrayVol',\n",
       " 'l_insula_ThickAvg',\n",
       " 'l_insula_ThickStd',\n",
       " 'l_insula_MeanCurv',\n",
       " 'l_caudalanteriorcingulate_GrayVol.1',\n",
       " 'l_caudalanteriorcingulate_MeanCurv.1',\n",
       " 'r_caudalanteriorcingulate_SurfArea',\n",
       " 'r_caudalanteriorcingulate_ThickAvg',\n",
       " 'r_caudalanteriorcingulate_ThickStd',\n",
       " 'r_caudalmiddlefrontal_GrayVol',\n",
       " 'r_caudalmiddlefrontal_MeanCurv',\n",
       " 'r_caudalmiddlefrontal_SurfArea',\n",
       " 'r_caudalmiddlefrontal_ThickAvg',\n",
       " 'r_caudalmiddlefrontal_ThickStd',\n",
       " 'r_cuneus_GrayVol',\n",
       " 'r_cuneus_MeanCurv',\n",
       " 'r_cuneus_SurfArea',\n",
       " 'r_cuneus_ThickAvg',\n",
       " 'r_cuneus_ThickStd',\n",
       " 'r_entorhinal_GrayVol',\n",
       " 'r_entorhinal_MeanCurv',\n",
       " 'r_entorhinal_SurfArea',\n",
       " 'r_entorhinal_ThickAvg',\n",
       " 'r_entorhinal_ThickStd',\n",
       " 'r_fusiform_GrayVol',\n",
       " 'r_fusiform_MeanCurv',\n",
       " 'r_fusiform_SurfArea',\n",
       " 'r_fusiform_ThickAvg',\n",
       " 'r_fusiform_ThickStd',\n",
       " 'r_inferiorparietal_GrayVol',\n",
       " 'r_inferiorparietal_MeanCurv',\n",
       " 'r_inferiorparietal_SurfArea',\n",
       " 'r_inferiorparietal_ThickAvg',\n",
       " 'r_inferiorparietal_ThickStd',\n",
       " 'r_inferiortemporal_GrayVol',\n",
       " 'r_inferiortemporal_MeanCurv',\n",
       " 'r_inferiortemporal_SurfArea',\n",
       " 'r_inferiortemporal_ThickAvg',\n",
       " 'r_inferiortemporal_ThickStd',\n",
       " 'r_insula_GrayVol',\n",
       " 'r_insula_MeanCurv',\n",
       " 'r_insula_SurfArea',\n",
       " 'r_insula_ThickAvg',\n",
       " 'r_insula_ThickStd',\n",
       " 'r_isthmuscingulate_GrayVol',\n",
       " 'r_isthmuscingulate_MeanCurv',\n",
       " 'r_isthmuscingulate_SurfArea',\n",
       " 'r_isthmuscingulate_ThickAvg',\n",
       " 'r_isthmuscingulate_ThickStd',\n",
       " 'r_lateraloccipital_GrayVol',\n",
       " 'r_lateraloccipital_MeanCurv',\n",
       " 'r_lateraloccipital_SurfArea',\n",
       " 'r_lateraloccipital_ThickAvg',\n",
       " 'r_lateraloccipital_ThickStd',\n",
       " 'r_lateralorbitofrontal_GrayVol',\n",
       " 'r_lateralorbitofrontal_MeanCurv',\n",
       " 'r_lateralorbitofrontal_SurfArea',\n",
       " 'r_lateralorbitofrontal_ThickAvg',\n",
       " 'r_lateralorbitofrontal_ThickStd',\n",
       " 'r_lingual_GrayVol',\n",
       " 'r_lingual_MeanCurv',\n",
       " 'r_lingual_SurfArea',\n",
       " 'r_lingual_ThickAvg',\n",
       " 'r_lingual_ThickStd',\n",
       " 'r_medialorbitofrontal_GrayVol',\n",
       " 'r_medialorbitofrontal_MeanCurv',\n",
       " 'r_medialorbitofrontal_SurfArea',\n",
       " 'r_medialorbitofrontal_ThickAvg',\n",
       " 'r_medialorbitofrontal_ThickStd',\n",
       " 'r_middletemporal_GrayVol',\n",
       " 'r_middletemporal_MeanCurv',\n",
       " 'r_middletemporal_SurfArea',\n",
       " 'r_middletemporal_ThickAvg',\n",
       " 'r_middletemporal_ThickStd',\n",
       " 'r_paracentral_GrayVol',\n",
       " 'r_paracentral_MeanCurv',\n",
       " 'r_paracentral_SurfArea',\n",
       " 'r_paracentral_ThickAvg',\n",
       " 'r_paracentral_ThickStd',\n",
       " 'r_parahippocampal_GrayVol',\n",
       " 'r_parahippocampal_MeanCurv',\n",
       " 'r_parahippocampal_SurfArea',\n",
       " 'r_parahippocampal_ThickAvg',\n",
       " 'r_parahippocampal_ThickStd',\n",
       " 'r_parsopercularis_GrayVol',\n",
       " 'r_parsopercularis_MeanCurv',\n",
       " 'r_parsopercularis_SurfArea',\n",
       " 'r_parsopercularis_ThickAvg',\n",
       " 'r_parsopercularis_ThickStd',\n",
       " 'r_parsorbitalis_GrayVol',\n",
       " 'r_parsorbitalis_MeanCurv',\n",
       " 'r_parsorbitalis_SurfArea',\n",
       " 'r_parsorbitalis_ThickAvg',\n",
       " 'r_parsorbitalis_ThickStd',\n",
       " 'r_parstriangularis_GrayVol',\n",
       " 'r_parstriangularis_MeanCurv',\n",
       " 'r_parstriangularis_SurfArea',\n",
       " 'r_parstriangularis_ThickAvg',\n",
       " 'r_parstriangularis_ThickStd',\n",
       " 'r_pericalcarine_GrayVol',\n",
       " 'r_pericalcarine_MeanCurv',\n",
       " 'r_pericalcarine_SurfArea',\n",
       " 'r_pericalcarine_ThickAvg',\n",
       " 'r_pericalcarine_ThickStd',\n",
       " 'r_postcentral_GrayVol',\n",
       " 'r_postcentral_MeanCurv',\n",
       " 'r_postcentral_SurfArea',\n",
       " 'r_postcentral_ThickAvg',\n",
       " 'r_postcentral_ThickStd',\n",
       " 'r_posteriorcingulate_GrayVol',\n",
       " 'r_posteriorcingulate_MeanCurv',\n",
       " 'r_posteriorcingulate_SurfArea',\n",
       " 'r_posteriorcingulate_ThickAvg',\n",
       " 'r_posteriorcingulate_ThickStd',\n",
       " 'r_precentral_GrayVol',\n",
       " 'r_precentral_MeanCurv',\n",
       " 'r_precentral_SurfArea',\n",
       " 'r_precentral_ThickAvg',\n",
       " 'r_precentral_ThickStd',\n",
       " 'r_precuneus_GrayVol',\n",
       " 'r_precuneus_MeanCurv',\n",
       " 'r_precuneus_SurfArea',\n",
       " 'r_precuneus_ThickAvg',\n",
       " 'r_precuneus_ThickStd',\n",
       " 'r_rostralanteriorcingulate_GrayVol',\n",
       " 'r_rostralanteriorcingulate_MeanCurv',\n",
       " 'r_rostralanteriorcingulate_SurfArea',\n",
       " 'r_rostralanteriorcingulate_ThickAvg',\n",
       " 'r_rostralanteriorcingulate_ThickStd',\n",
       " 'r_rostralmiddlefrontal_GrayVol',\n",
       " 'r_rostralmiddlefrontal_MeanCurv',\n",
       " 'r_rostralmiddlefrontal_SurfArea',\n",
       " 'r_rostralmiddlefrontal_ThickAvg',\n",
       " 'r_rostralmiddlefrontal_ThickStd',\n",
       " 'r_superiorfrontal_GrayVol',\n",
       " 'r_superiorfrontal_MeanCurv',\n",
       " 'r_superiorfrontal_SurfArea',\n",
       " 'r_superiorfrontal_ThickAvg',\n",
       " 'r_superiorfrontal_ThickStd',\n",
       " 'r_superiorparietal_GrayVol',\n",
       " 'r_superiorparietal_MeanCurv',\n",
       " 'r_superiorparietal_SurfArea',\n",
       " 'r_superiorparietal_ThickAvg',\n",
       " 'r_superiorparietal_ThickStd',\n",
       " 'r_superiortemporal_GrayVol',\n",
       " 'r_superiortemporal_MeanCurv',\n",
       " 'r_superiortemporal_SurfArea',\n",
       " 'r_superiortemporal_ThickAvg',\n",
       " 'r_superiortemporal_ThickStd',\n",
       " 'r_supramarginal_GrayVol',\n",
       " 'r_supramarginal_MeanCurv',\n",
       " 'r_supramarginal_SurfArea',\n",
       " 'r_supramarginal_ThickAvg',\n",
       " 'r_supramarginal_ThickStd',\n",
       " 'r_temporalpole_GrayVol',\n",
       " 'r_temporalpole_MeanCurv',\n",
       " 'r_temporalpole_SurfArea',\n",
       " 'r_temporalpole_ThickAvg',\n",
       " 'r_temporalpole_ThickStd',\n",
       " 'r_transversetemporal_GrayVol',\n",
       " 'r_transversetemporal_MeanCurv',\n",
       " 'r_transversetemporal_SurfArea',\n",
       " 'r_transversetemporal_ThickAvg',\n",
       " 'r_transversetemporal_ThickStd',\n",
       " 'caudalanteriorcingulate_SurfArea',\n",
       " 'caudalanteriorcingulate_GrayVol',\n",
       " 'caudalanteriorcingulate_ThickAvg',\n",
       " 'caudalanteriorcingulate_ThickStd',\n",
       " 'caudalanteriorcingulate_MeanCurv',\n",
       " 'caudalmiddlefrontal_SurfArea',\n",
       " 'caudalmiddlefrontal_GrayVol',\n",
       " 'caudalmiddlefrontal_ThickAvg',\n",
       " 'caudalmiddlefrontal_ThickStd',\n",
       " 'caudalmiddlefrontal_MeanCurv',\n",
       " 'cuneus_SurfArea',\n",
       " 'cuneus_GrayVol',\n",
       " 'cuneus_ThickAvg',\n",
       " 'cuneus_ThickStd',\n",
       " 'cuneus_MeanCurv',\n",
       " 'entorhinal_SurfArea',\n",
       " 'entorhinal_GrayVol',\n",
       " 'entorhinal_ThickAvg',\n",
       " 'entorhinal_ThickStd',\n",
       " 'entorhinal_MeanCurv',\n",
       " 'fusiform_SurfArea',\n",
       " 'fusiform_GrayVol',\n",
       " 'fusiform_ThickAvg',\n",
       " 'fusiform_ThickStd',\n",
       " 'fusiform_MeanCurv',\n",
       " 'inferiorparietal_SurfArea',\n",
       " 'inferiorparietal_GrayVol',\n",
       " 'inferiorparietal_ThickAvg',\n",
       " 'inferiorparietal_ThickStd',\n",
       " 'inferiorparietal_MeanCurv',\n",
       " 'inferiortemporal_SurfArea',\n",
       " 'inferiortemporal_GrayVol',\n",
       " 'inferiortemporal_ThickAvg',\n",
       " 'inferiortemporal_ThickStd',\n",
       " 'inferiortemporal_MeanCurv',\n",
       " 'isthmuscingulate_SurfArea',\n",
       " 'isthmuscingulate_GrayVol',\n",
       " 'isthmuscingulate_ThickAvg',\n",
       " 'isthmuscingulate_ThickStd',\n",
       " 'isthmuscingulate_MeanCurv',\n",
       " 'lateraloccipital_SurfArea',\n",
       " 'lateraloccipital_GrayVol',\n",
       " 'lateraloccipital_ThickAvg',\n",
       " 'lateraloccipital_ThickStd',\n",
       " 'lateraloccipital_MeanCurv',\n",
       " 'lateralorbitofrontal_SurfArea',\n",
       " 'lateralorbitofrontal_GrayVol',\n",
       " 'lateralorbitofrontal_ThickAvg',\n",
       " 'lateralorbitofrontal_ThickStd',\n",
       " 'lateralorbitofrontal_MeanCurv',\n",
       " 'lingual_SurfArea',\n",
       " 'lingual_GrayVol',\n",
       " 'lingual_ThickAvg',\n",
       " 'lingual_ThickStd',\n",
       " 'lingual_MeanCurv',\n",
       " 'medialorbitofrontal_SurfArea',\n",
       " 'medialorbitofrontal_GrayVol',\n",
       " 'medialorbitofrontal_ThickAvg',\n",
       " 'medialorbitofrontal_ThickStd',\n",
       " 'medialorbitofrontal_MeanCurv',\n",
       " 'middletemporal_SurfArea',\n",
       " 'middletemporal_GrayVol',\n",
       " 'middletemporal_ThickAvg',\n",
       " 'middletemporal_ThickStd',\n",
       " 'middletemporal_MeanCurv',\n",
       " 'parahippocampal_SurfArea',\n",
       " 'parahippocampal_GrayVol',\n",
       " 'parahippocampal_ThickAvg',\n",
       " 'parahippocampal_ThickStd',\n",
       " 'parahippocampal_MeanCurv',\n",
       " 'paracentral_SurfArea',\n",
       " 'paracentral_GrayVol',\n",
       " 'paracentral_ThickAvg',\n",
       " 'paracentral_ThickStd',\n",
       " 'paracentral_MeanCurv',\n",
       " 'parsopercularis_SurfArea',\n",
       " 'parsopercularis_GrayVol',\n",
       " 'parsopercularis_ThickAvg',\n",
       " 'parsopercularis_ThickStd',\n",
       " 'parsopercularis_MeanCurv',\n",
       " 'parsorbitalis_SurfArea',\n",
       " 'parsorbitalis_GrayVol',\n",
       " 'parsorbitalis_ThickAvg',\n",
       " 'parsorbitalis_ThickStd',\n",
       " 'parsorbitalis_MeanCurv',\n",
       " 'parstriangularis_SurfArea',\n",
       " 'parstriangularis_GrayVol',\n",
       " 'parstriangularis_ThickAvg',\n",
       " 'parstriangularis_ThickStd',\n",
       " 'parstriangularis_MeanCurv',\n",
       " 'pericalcarine_SurfArea',\n",
       " 'pericalcarine_GrayVol',\n",
       " 'pericalcarine_ThickAvg',\n",
       " 'pericalcarine_ThickStd',\n",
       " 'pericalcarine_MeanCurv',\n",
       " 'postcentral_SurfArea',\n",
       " 'postcentral_GrayVol',\n",
       " 'postcentral_ThickAvg',\n",
       " 'postcentral_ThickStd',\n",
       " 'postcentral_MeanCurv',\n",
       " 'posteriorcingulate_SurfArea',\n",
       " 'posteriorcingulate_GrayVol',\n",
       " 'posteriorcingulate_ThickAvg',\n",
       " 'posteriorcingulate_ThickStd',\n",
       " 'posteriorcingulate_MeanCurv',\n",
       " 'precentral_SurfArea',\n",
       " 'precentral_GrayVol',\n",
       " 'precentral_ThickAvg',\n",
       " 'precentral_ThickStd',\n",
       " 'precentral_MeanCurv',\n",
       " 'precuneus_SurfArea',\n",
       " 'precuneus_GrayVol',\n",
       " 'precuneus_ThickAvg',\n",
       " 'precuneus_ThickStd',\n",
       " 'precuneus_MeanCurv',\n",
       " 'rostralanteriorcingulate_SurfArea',\n",
       " 'rostralanteriorcingulate_GrayVol',\n",
       " 'rostralanteriorcingulate_ThickAvg',\n",
       " 'rostralanteriorcingulate_ThickStd',\n",
       " 'rostralanteriorcingulate_MeanCurv',\n",
       " 'rostralmiddlefrontal_SurfArea',\n",
       " 'rostralmiddlefrontal_GrayVol',\n",
       " 'rostralmiddlefrontal_ThickAvg',\n",
       " 'rostralmiddlefrontal_ThickStd',\n",
       " 'rostralmiddlefrontal_MeanCurv',\n",
       " 'superiorfrontal_SurfArea',\n",
       " 'superiorfrontal_GrayVol',\n",
       " 'superiorfrontal_ThickAvg',\n",
       " 'superiorfrontal_ThickStd',\n",
       " 'superiorfrontal_MeanCurv',\n",
       " 'superiorparietal_SurfArea',\n",
       " 'superiorparietal_GrayVol',\n",
       " 'superiorparietal_ThickAvg',\n",
       " 'superiorparietal_ThickStd',\n",
       " 'superiorparietal_MeanCurv',\n",
       " 'superiortemporal_SurfArea',\n",
       " 'superiortemporal_GrayVol',\n",
       " 'superiortemporal_ThickAvg',\n",
       " 'superiortemporal_ThickStd',\n",
       " 'superiortemporal_MeanCurv',\n",
       " 'supramarginal_SurfArea',\n",
       " 'supramarginal_GrayVol',\n",
       " 'supramarginal_ThickAvg',\n",
       " 'supramarginal_ThickStd',\n",
       " 'supramarginal_MeanCurv',\n",
       " 'transversetemporal_SurfArea',\n",
       " 'transversetemporal_GrayVol',\n",
       " 'transversetemporal_ThickAvg',\n",
       " 'transversetemporal_ThickStd',\n",
       " 'transversetemporal_MeanCurv',\n",
       " 'insula_SurfArea',\n",
       " 'insula_GrayVol',\n",
       " 'insula_ThickAvg',\n",
       " 'insula_ThickStd',\n",
       " 'insula_MeanCurv',\n",
       " 'grupa',\n",
       " 'sex',\n",
       " 'recon_all',\n",
       " ' Brain Segmentation Volume (mm3)',\n",
       " ' Brain Segmentation Volume Without Ventricles (mm3)',\n",
       " ' Brain Segmentation Volume Without Ventricles from Surf (mm3)',\n",
       " ' Volume of ventricles and choroid plexus (mm3)',\n",
       " ' Left hemisphere cortical gray matter volume (mm3)',\n",
       " ' Right hemisphere cortical gray matter volume (mm3)',\n",
       " ' Total cortical gray matter volume (mm3)',\n",
       " ' Left hemisphere cerebral white matter volume (mm3)',\n",
       " ' Right hemisphere cerebral white matter volume (mm3)',\n",
       " ' Total cerebral white matter volume (mm3)',\n",
       " ' Subcortical gray matter volume (mm3)',\n",
       " ' Total gray matter volume (mm3)',\n",
       " ' Supratentorial volume (mm3)',\n",
       " ' Supratentorial volume (mm3)2',\n",
       " ' Supratentorial volume voxel count (mm3)',\n",
       " ' Mask Volume (mm3)',\n",
       " ' Ratio of BrainSegVol to eTIV (unitless)',\n",
       " ' Ratio of MaskVol to eTIV (unitless)',\n",
       " ' Number of defect holes in lh surfaces prior to fixing (unitless)',\n",
       " ' Number of defect holes in rh surfaces prior to fixing (unitless)',\n",
       " ' Total number of defect holes in surfaces prior to fixing (unitless)',\n",
       " ' Estimated Total Intracranial Volume (mm3)',\n",
       " 'recon_all2',\n",
       " 'lh_Thalamus_index',\n",
       " 'lh_thalamus_SegId',\n",
       " 'lh_Thalamus_Nvoxels',\n",
       " 'lh_Thalamus_volume_mm3',\n",
       " 'normMean',\n",
       " 'normStdDev',\n",
       " 'normMin',\n",
       " 'normMax',\n",
       " 'normRange ',\n",
       " 'rh_Thalamus_index',\n",
       " 'rh_thalamus_SegId',\n",
       " 'rh_Thalamus_Nvoxels',\n",
       " 'rh_Thalamus_volume_mm3',\n",
       " 'normMean2',\n",
       " 'normStdDev2',\n",
       " 'normMin2',\n",
       " 'normMax2',\n",
       " 'normRange',\n",
       " 'recon_all222',\n",
       " 'lh_Caudate_index3',\n",
       " 'lh_Caudate_SegId4',\n",
       " 'lh_Caudate_Nvoxels5',\n",
       " 'lh_Caudate_volume_mm366',\n",
       " 'normMean37',\n",
       " 'normStdDev38',\n",
       " 'normMin39',\n",
       " 'normMax310',\n",
       " 'normRange 211',\n",
       " 'rh_Caudate_index12',\n",
       " 'rh_Caudate_SegId13',\n",
       " 'rh_Caudate_Nvoxels14',\n",
       " 'rh_Caudate_volume_mm315',\n",
       " 'normMean416',\n",
       " 'normStdDev417',\n",
       " 'normMin418',\n",
       " 'normMax419',\n",
       " 'normRange220',\n",
       " 'recon_all2222',\n",
       " 'lh_Putamen_index',\n",
       " 'lh_Putamen_SegId',\n",
       " 'lh_Putamen_Nvoxels55',\n",
       " 'lh_Putamen_volume_mm3666',\n",
       " 'normMean3',\n",
       " 'normStdDev388',\n",
       " 'normMin399',\n",
       " 'normMax31010',\n",
       " 'normRange 21111',\n",
       " 'rh_Putamen_index1212',\n",
       " 'rh_Putamen_SegId1313',\n",
       " 'rh_Putamen_Nvoxels1414',\n",
       " 'rh_Putamen_volume_mm31515',\n",
       " 'normMean41616',\n",
       " 'normStdDev41717',\n",
       " 'normMin41818',\n",
       " 'normMax41919',\n",
       " 'normRange22020',\n",
       " 'recon_all22222',\n",
       " 'lh_Pallidum_index3',\n",
       " 'lh_Pallidum_SegId4',\n",
       " 'lh_Pallidum_Nvoxels555',\n",
       " 'lh_Pallidum_volume_mm3',\n",
       " 'normMean38',\n",
       " 'normStdDev3889',\n",
       " 'normMin39910',\n",
       " 'normMax3101011',\n",
       " 'normRange 2111112',\n",
       " 'rh_Pallidum_index121213',\n",
       " 'rh_Pallidum_SegId131314',\n",
       " 'rh_Pallidum_Nvoxels141415',\n",
       " 'rh_Pallidum_volume_mm3151516',\n",
       " 'normMean4161617',\n",
       " 'normStdDev4171718',\n",
       " 'normMin4181819',\n",
       " 'normMax4191920',\n",
       " 'normRange2202021',\n",
       " 'lh_Hippocampus_index32',\n",
       " 'lh_Hippocampus_SegId43',\n",
       " 'lh_Hippocampus_Nvoxels5554',\n",
       " 'lh_Hippocampus_volume_mm35',\n",
       " 'normMean386',\n",
       " 'normStdDev38897',\n",
       " 'normMin399108',\n",
       " 'normMax31010119',\n",
       " 'normRange 211111210',\n",
       " 'rh_Hippocampus_index12121311',\n",
       " 'rh_Hippocampus_SegId13131412',\n",
       " 'rh_Hippocampus_Nvoxels14141513',\n",
       " 'rh_Hippocampus_volume_mm315151614',\n",
       " 'normMean416161715',\n",
       " 'normStdDev417171816',\n",
       " 'normMin418181917',\n",
       " 'normMax419192018',\n",
       " 'normRange220202119',\n",
       " 'lh_Amygdala_index322',\n",
       " 'lh_Amygdala_SegId433',\n",
       " 'lh_Amygdala_Nvoxels55544',\n",
       " 'lh_Amygdala_volume_mm355',\n",
       " 'normMean3866',\n",
       " 'normStdDev388977',\n",
       " 'normMin3991088',\n",
       " 'normMax310101199',\n",
       " 'normRange5',\n",
       " 'rh_Amygdala_index',\n",
       " 'rh_Amygdala_SegId',\n",
       " 'rh_Amygdala_Nvoxels',\n",
       " 'rh_Amygdala_volume_mm3',\n",
       " 'normMean6',\n",
       " 'normStdDev5',\n",
       " 'normMin5',\n",
       " 'normMax5',\n",
       " 'normRange4',\n",
       " 'recon_all3',\n",
       " 'CSF_index',\n",
       " 'CSF_SegId',\n",
       " 'CSF_Nvoxels',\n",
       " 'CSF_volume_mm3',\n",
       " 'normMean5',\n",
       " 'normStdDev4',\n",
       " 'normMin4',\n",
       " 'normMax4',\n",
       " 'normRange3',\n",
       " 'BrainStem_index',\n",
       " 'BrainStem_SegId',\n",
       " 'BrainStem_Nvoxels',\n",
       " 'BrainStem_volume_mm3',\n",
       " 'normMean4',\n",
       " 'normStdDev3',\n",
       " 'normMin3',\n",
       " 'normMax3',\n",
       " 'normRange2']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=data.replace({'grupa': {'smoker': 1, 'non-smoker': 0}})\n",
    "#data=data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['recon_all2', 'recon_all222', 'recon_all2222', 'recon_all22222', 'recon_all3'], axis=1)\n",
    "data = data.drop(['id', 'recon_all', 'r_insula_MeanCurv', 'r_temporalpole_MeanCurv','r_temporalpole_GrayVol', 'r_insula_GrayVol', 'r_insula_ThickAvg', 'r_temporalpole_ThickAvg'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_mm3 = data.filter(regex='mm3', axis=1)\n",
    "data_vol = data.filter(regex='_GrayVol', axis=1)\n",
    "data_thick = data.filter(regex='_ThickAvg', axis=1)\n",
    "data_curv = data.filter(regex='_MeanCurv', axis=1)\n",
    "#data_surfa = data.filter(regex='SurfArea', axis=1)\n",
    "data_left_right_overall = data[data.columns[0:10]]\n",
    "grupa = data[['grupa']]\n",
    "sex = data[['sex']]\n",
    "\n",
    "data = pd.concat([grupa, sex, data_mm3, data_vol, data_thick, data_left_right_overall, data_curv], axis=1, join_axes=[data_mm3.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 319)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEcCAYAAAAYxrniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMysdA4+ZmZWOgcfMzMr3f8C34lbxMmKTtgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1160aa0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brain_vol=data.boxplot(column=' Brain Segmentation Volume (mm3)',by='grupa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEcCAYAAAD6GqKbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11792f7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grey_vol=data.boxplot(column=' Total gray matter volume (mm3)',by='grupa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEcCAYAAAD6GqKbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9ZCgAEVtDZQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1214bb710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grey_cortical_vol=data.boxplot(column=' Total cortical gray matter volume (mm3)', by = 'grupa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confounding Factor Analysis\n",
    "TODO : fill it in\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature Selection \n",
    "\n",
    "Monitored the stability of the selection algorithm with the Jaccard index.\n",
    "Computed the feature selection frequency across all CV iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization (standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grupa',\n",
       " 'sex',\n",
       " ' Brain Segmentation Volume (mm3)',\n",
       " ' Brain Segmentation Volume Without Ventricles (mm3)',\n",
       " ' Brain Segmentation Volume Without Ventricles from Surf (mm3)',\n",
       " ' Volume of ventricles and choroid plexus (mm3)',\n",
       " ' Left hemisphere cortical gray matter volume (mm3)',\n",
       " ' Right hemisphere cortical gray matter volume (mm3)',\n",
       " ' Total cortical gray matter volume (mm3)',\n",
       " ' Left hemisphere cerebral white matter volume (mm3)',\n",
       " ' Right hemisphere cerebral white matter volume (mm3)',\n",
       " ' Total cerebral white matter volume (mm3)',\n",
       " ' Subcortical gray matter volume (mm3)',\n",
       " ' Total gray matter volume (mm3)',\n",
       " ' Supratentorial volume (mm3)',\n",
       " ' Supratentorial volume (mm3)2',\n",
       " ' Supratentorial volume voxel count (mm3)',\n",
       " ' Mask Volume (mm3)',\n",
       " ' Estimated Total Intracranial Volume (mm3)',\n",
       " 'lh_Thalamus_volume_mm3',\n",
       " 'rh_Thalamus_volume_mm3',\n",
       " 'lh_Caudate_volume_mm366',\n",
       " 'rh_Caudate_volume_mm315',\n",
       " 'lh_Putamen_volume_mm3666',\n",
       " 'rh_Putamen_volume_mm31515',\n",
       " 'lh_Pallidum_volume_mm3',\n",
       " 'rh_Pallidum_volume_mm3151516',\n",
       " 'lh_Hippocampus_volume_mm35',\n",
       " 'rh_Hippocampus_volume_mm315151614',\n",
       " 'lh_Amygdala_volume_mm355',\n",
       " 'rh_Amygdala_volume_mm3',\n",
       " 'CSF_volume_mm3',\n",
       " 'BrainStem_volume_mm3',\n",
       " 'l_caudalanteriorcingulate_GrayVol',\n",
       " 'l_caudalmiddlefrontal_GrayVol',\n",
       " 'l_cuneus_GrayVol',\n",
       " 'l_entorhinal_GrayVol',\n",
       " 'l_fusiform_GrayVol',\n",
       " 'l_inferiorparietal_GrayVol',\n",
       " 'l_inferiortemporal_GrayVol',\n",
       " 'l_isthmuscingulate_GrayVol',\n",
       " 'l_lateraloccipital_GrayVol',\n",
       " 'l_lateralorbitofrontal_GrayVol',\n",
       " 'l_lingual_GrayVol',\n",
       " 'l_medialorbitofrontal_GrayVol',\n",
       " 'l_middletemporal_GrayVol',\n",
       " 'l_parahippocampal_GrayVol',\n",
       " 'l_paracentral_GrayVol',\n",
       " 'l_parsopercularis_GrayVol',\n",
       " 'l_parsorbitalis_GrayVol',\n",
       " 'l_parstriangularis_GrayVol',\n",
       " 'l_pericalcarine_GrayVol',\n",
       " 'l_postcentral_GrayVol',\n",
       " 'l_posteriorcingulate_GrayVol',\n",
       " 'l_precentral_GrayVol',\n",
       " 'l_precuneus_GrayVol',\n",
       " 'l_rostralanteriorcingulate_GrayVol',\n",
       " 'l_rostralmiddlefrontal_GrayVol',\n",
       " 'l_superiorfrontal_GrayVol',\n",
       " 'l_superiorparietal_GrayVol',\n",
       " 'l_superiortemporal_GrayVol',\n",
       " 'l_supramarginal_GrayVol',\n",
       " 'l_transversetemporal_GrayVol',\n",
       " 'l_insula_GrayVol',\n",
       " 'l_caudalanteriorcingulate_GrayVol.1',\n",
       " 'r_caudalmiddlefrontal_GrayVol',\n",
       " 'r_cuneus_GrayVol',\n",
       " 'r_entorhinal_GrayVol',\n",
       " 'r_fusiform_GrayVol',\n",
       " 'r_inferiorparietal_GrayVol',\n",
       " 'r_inferiortemporal_GrayVol',\n",
       " 'r_isthmuscingulate_GrayVol',\n",
       " 'r_lateraloccipital_GrayVol',\n",
       " 'r_lateralorbitofrontal_GrayVol',\n",
       " 'r_lingual_GrayVol',\n",
       " 'r_medialorbitofrontal_GrayVol',\n",
       " 'r_middletemporal_GrayVol',\n",
       " 'r_paracentral_GrayVol',\n",
       " 'r_parahippocampal_GrayVol',\n",
       " 'r_parsopercularis_GrayVol',\n",
       " 'r_parsorbitalis_GrayVol',\n",
       " 'r_parstriangularis_GrayVol',\n",
       " 'r_pericalcarine_GrayVol',\n",
       " 'r_postcentral_GrayVol',\n",
       " 'r_posteriorcingulate_GrayVol',\n",
       " 'r_precentral_GrayVol',\n",
       " 'r_precuneus_GrayVol',\n",
       " 'r_rostralanteriorcingulate_GrayVol',\n",
       " 'r_rostralmiddlefrontal_GrayVol',\n",
       " 'r_superiorfrontal_GrayVol',\n",
       " 'r_superiorparietal_GrayVol',\n",
       " 'r_superiortemporal_GrayVol',\n",
       " 'r_supramarginal_GrayVol',\n",
       " 'r_transversetemporal_GrayVol',\n",
       " 'caudalanteriorcingulate_GrayVol',\n",
       " 'caudalmiddlefrontal_GrayVol',\n",
       " 'cuneus_GrayVol',\n",
       " 'entorhinal_GrayVol',\n",
       " 'fusiform_GrayVol',\n",
       " 'inferiorparietal_GrayVol',\n",
       " 'inferiortemporal_GrayVol',\n",
       " 'isthmuscingulate_GrayVol',\n",
       " 'lateraloccipital_GrayVol',\n",
       " 'lateralorbitofrontal_GrayVol',\n",
       " 'lingual_GrayVol',\n",
       " 'medialorbitofrontal_GrayVol',\n",
       " 'middletemporal_GrayVol',\n",
       " 'parahippocampal_GrayVol',\n",
       " 'paracentral_GrayVol',\n",
       " 'parsopercularis_GrayVol',\n",
       " 'parsorbitalis_GrayVol',\n",
       " 'parstriangularis_GrayVol',\n",
       " 'pericalcarine_GrayVol',\n",
       " 'postcentral_GrayVol',\n",
       " 'posteriorcingulate_GrayVol',\n",
       " 'precentral_GrayVol',\n",
       " 'precuneus_GrayVol',\n",
       " 'rostralanteriorcingulate_GrayVol',\n",
       " 'rostralmiddlefrontal_GrayVol',\n",
       " 'superiorfrontal_GrayVol',\n",
       " 'superiorparietal_GrayVol',\n",
       " 'superiortemporal_GrayVol',\n",
       " 'supramarginal_GrayVol',\n",
       " 'transversetemporal_GrayVol',\n",
       " 'insula_GrayVol',\n",
       " 'l_caudalanteriorcingulate_ThickAvg',\n",
       " 'l_caudalmiddlefrontal_ThickAvg',\n",
       " 'l_cuneus_ThickAvg',\n",
       " 'l_entorhinal_ThickAvg',\n",
       " 'l_fusiform_ThickAvg',\n",
       " 'l_inferiorparietal_ThickAvg',\n",
       " 'l_inferiortemporal_ThickAvg',\n",
       " 'l_isthmuscingulate_ThickAvg',\n",
       " 'l_lateraloccipital_ThickAvg',\n",
       " 'l_lateralorbitofrontal_ThickAvg',\n",
       " 'l_lingual_ThickAvg',\n",
       " 'l_medialorbitofrontal_ThickAvg',\n",
       " 'l_middletemporal_ThickAvg',\n",
       " 'l_parahippocampal_ThickAvg',\n",
       " 'l_paracentral_ThickAvg',\n",
       " 'l_parsopercularis_ThickAvg',\n",
       " 'l_parsorbitalis_ThickAvg',\n",
       " 'l_parstriangularis_ThickAvg',\n",
       " 'l_pericalcarine_ThickAvg',\n",
       " 'l_postcentral_ThickAvg',\n",
       " 'l_posteriorcingulate_ThickAvg',\n",
       " 'l_precentral_ThickAvg',\n",
       " 'l_precuneus_ThickAvg',\n",
       " 'l_rostralanteriorcingulate_ThickAvg',\n",
       " 'l_rostralmiddlefrontal_ThickAvg',\n",
       " 'l_superiorfrontal_ThickAvg',\n",
       " 'l_superiorparietal_ThickAvg',\n",
       " 'l_superiortemporal_ThickAvg',\n",
       " 'l_supramarginal_ThickAvg',\n",
       " 'l_transversetemporal_ThickAvg',\n",
       " 'l_insula_ThickAvg',\n",
       " 'r_caudalanteriorcingulate_ThickAvg',\n",
       " 'r_caudalmiddlefrontal_ThickAvg',\n",
       " 'r_cuneus_ThickAvg',\n",
       " 'r_entorhinal_ThickAvg',\n",
       " 'r_fusiform_ThickAvg',\n",
       " 'r_inferiorparietal_ThickAvg',\n",
       " 'r_inferiortemporal_ThickAvg',\n",
       " 'r_isthmuscingulate_ThickAvg',\n",
       " 'r_lateraloccipital_ThickAvg',\n",
       " 'r_lateralorbitofrontal_ThickAvg',\n",
       " 'r_lingual_ThickAvg',\n",
       " 'r_medialorbitofrontal_ThickAvg',\n",
       " 'r_middletemporal_ThickAvg',\n",
       " 'r_paracentral_ThickAvg',\n",
       " 'r_parahippocampal_ThickAvg',\n",
       " 'r_parsopercularis_ThickAvg',\n",
       " 'r_parsorbitalis_ThickAvg',\n",
       " 'r_parstriangularis_ThickAvg',\n",
       " 'r_pericalcarine_ThickAvg',\n",
       " 'r_postcentral_ThickAvg',\n",
       " 'r_posteriorcingulate_ThickAvg',\n",
       " 'r_precentral_ThickAvg',\n",
       " 'r_precuneus_ThickAvg',\n",
       " 'r_rostralanteriorcingulate_ThickAvg',\n",
       " 'r_rostralmiddlefrontal_ThickAvg',\n",
       " 'r_superiorfrontal_ThickAvg',\n",
       " 'r_superiorparietal_ThickAvg',\n",
       " 'r_superiortemporal_ThickAvg',\n",
       " 'r_supramarginal_ThickAvg',\n",
       " 'r_transversetemporal_ThickAvg',\n",
       " 'caudalanteriorcingulate_ThickAvg',\n",
       " 'caudalmiddlefrontal_ThickAvg',\n",
       " 'cuneus_ThickAvg',\n",
       " 'entorhinal_ThickAvg',\n",
       " 'fusiform_ThickAvg',\n",
       " 'inferiorparietal_ThickAvg',\n",
       " 'inferiortemporal_ThickAvg',\n",
       " 'isthmuscingulate_ThickAvg',\n",
       " 'lateraloccipital_ThickAvg',\n",
       " 'lateralorbitofrontal_ThickAvg',\n",
       " 'lingual_ThickAvg',\n",
       " 'medialorbitofrontal_ThickAvg',\n",
       " 'middletemporal_ThickAvg',\n",
       " 'parahippocampal_ThickAvg',\n",
       " 'paracentral_ThickAvg',\n",
       " 'parsopercularis_ThickAvg',\n",
       " 'parsorbitalis_ThickAvg',\n",
       " 'parstriangularis_ThickAvg',\n",
       " 'pericalcarine_ThickAvg',\n",
       " 'postcentral_ThickAvg',\n",
       " 'posteriorcingulate_ThickAvg',\n",
       " 'precentral_ThickAvg',\n",
       " 'precuneus_ThickAvg',\n",
       " 'rostralanteriorcingulate_ThickAvg',\n",
       " 'rostralmiddlefrontal_ThickAvg',\n",
       " 'superiorfrontal_ThickAvg',\n",
       " 'superiorparietal_ThickAvg',\n",
       " 'superiortemporal_ThickAvg',\n",
       " 'supramarginal_ThickAvg',\n",
       " 'transversetemporal_ThickAvg',\n",
       " 'insula_ThickAvg',\n",
       " ' L Cortex White Surface Total Area',\n",
       " ' L Cortex Mean Thickness',\n",
       " ' L Brain Segmentation Volume',\n",
       " ' L Brain Segmentation Volume Without Ventricles',\n",
       " 'L  Brain Segmentation Volume Without Ventricles from Surf',\n",
       " ' R Cortex White Surface Total Area',\n",
       " ' R Cortex Mean Thickness',\n",
       " 'R  Brain Segmentation Volume',\n",
       " 'R Brain Segmentation Volume Without Ventricles',\n",
       " ' R Brain Segmentation Volume Without Ventricles from Surf',\n",
       " 'l_caudalanteriorcingulate_MeanCurv',\n",
       " 'l_caudalmiddlefrontal_MeanCurv',\n",
       " 'l_cuneus_MeanCurv',\n",
       " 'l_entorhinal_MeanCurv',\n",
       " 'l_fusiform_MeanCurv',\n",
       " 'l_inferiorparietal_MeanCurv',\n",
       " 'l_inferiortemporal_MeanCurv',\n",
       " 'l_isthmuscingulate_MeanCurv',\n",
       " 'l_lateraloccipital_MeanCurv',\n",
       " 'l_lateralorbitofrontal_MeanCurv',\n",
       " 'l_lingual_MeanCurv',\n",
       " 'l_medialorbitofrontal_MeanCurv',\n",
       " 'l_middletemporal_MeanCurv',\n",
       " 'l_parahippocampal_MeanCurv',\n",
       " 'l_paracentral_MeanCurv',\n",
       " 'l_parsopercularis_MeanCurv',\n",
       " 'l_parsorbitalis_MeanCurv',\n",
       " 'l_parstriangularis_MeanCurv',\n",
       " 'l_pericalcarine_MeanCurv',\n",
       " 'l_postcentral_MeanCurv',\n",
       " 'l_posteriorcingulate_MeanCurv',\n",
       " 'l_precentral_MeanCurv',\n",
       " 'l_precuneus_MeanCurv',\n",
       " 'l_rostralanteriorcingulate_MeanCurv',\n",
       " 'l_rostralmiddlefrontal_MeanCurv',\n",
       " 'l_superiorfrontal_MeanCurv',\n",
       " 'l_superiorparietal_MeanCurv',\n",
       " 'l_superiortemporal_MeanCurv',\n",
       " 'l_supramarginal_MeanCurv',\n",
       " 'l_transversetemporal_MeanCurv',\n",
       " 'l_insula_MeanCurv',\n",
       " 'l_caudalanteriorcingulate_MeanCurv.1',\n",
       " 'r_caudalmiddlefrontal_MeanCurv',\n",
       " 'r_cuneus_MeanCurv',\n",
       " 'r_entorhinal_MeanCurv',\n",
       " 'r_fusiform_MeanCurv',\n",
       " 'r_inferiorparietal_MeanCurv',\n",
       " 'r_inferiortemporal_MeanCurv',\n",
       " 'r_isthmuscingulate_MeanCurv',\n",
       " 'r_lateraloccipital_MeanCurv',\n",
       " 'r_lateralorbitofrontal_MeanCurv',\n",
       " 'r_lingual_MeanCurv',\n",
       " 'r_medialorbitofrontal_MeanCurv',\n",
       " 'r_middletemporal_MeanCurv',\n",
       " 'r_paracentral_MeanCurv',\n",
       " 'r_parahippocampal_MeanCurv',\n",
       " 'r_parsopercularis_MeanCurv',\n",
       " 'r_parsorbitalis_MeanCurv',\n",
       " 'r_parstriangularis_MeanCurv',\n",
       " 'r_pericalcarine_MeanCurv',\n",
       " 'r_postcentral_MeanCurv',\n",
       " 'r_posteriorcingulate_MeanCurv',\n",
       " 'r_precentral_MeanCurv',\n",
       " 'r_precuneus_MeanCurv',\n",
       " 'r_rostralanteriorcingulate_MeanCurv',\n",
       " 'r_rostralmiddlefrontal_MeanCurv',\n",
       " 'r_superiorfrontal_MeanCurv',\n",
       " 'r_superiorparietal_MeanCurv',\n",
       " 'r_superiortemporal_MeanCurv',\n",
       " 'r_supramarginal_MeanCurv',\n",
       " 'r_transversetemporal_MeanCurv',\n",
       " 'caudalanteriorcingulate_MeanCurv',\n",
       " 'caudalmiddlefrontal_MeanCurv',\n",
       " 'cuneus_MeanCurv',\n",
       " 'entorhinal_MeanCurv',\n",
       " 'fusiform_MeanCurv',\n",
       " 'inferiorparietal_MeanCurv',\n",
       " 'inferiortemporal_MeanCurv',\n",
       " 'isthmuscingulate_MeanCurv',\n",
       " 'lateraloccipital_MeanCurv',\n",
       " 'lateralorbitofrontal_MeanCurv',\n",
       " 'lingual_MeanCurv',\n",
       " 'medialorbitofrontal_MeanCurv',\n",
       " 'middletemporal_MeanCurv',\n",
       " 'parahippocampal_MeanCurv',\n",
       " 'paracentral_MeanCurv',\n",
       " 'parsopercularis_MeanCurv',\n",
       " 'parsorbitalis_MeanCurv',\n",
       " 'parstriangularis_MeanCurv',\n",
       " 'pericalcarine_MeanCurv',\n",
       " 'postcentral_MeanCurv',\n",
       " 'posteriorcingulate_MeanCurv',\n",
       " 'precentral_MeanCurv',\n",
       " 'precuneus_MeanCurv',\n",
       " 'rostralanteriorcingulate_MeanCurv',\n",
       " 'rostralmiddlefrontal_MeanCurv',\n",
       " 'superiorfrontal_MeanCurv',\n",
       " 'superiorparietal_MeanCurv',\n",
       " 'superiortemporal_MeanCurv',\n",
       " 'supramarginal_MeanCurv',\n",
       " 'transversetemporal_MeanCurv',\n",
       " 'insula_MeanCurv']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalizing volume as a proportion to total volume\n",
    "\n",
    "#volume = data.filter(regex='_mm3', axis=1)\n",
    "#data[list(volume)].div(data[' Brain Segmentation Volume (mm3)'], axis=0)\n",
    "\n",
    "#gray_volume = data.filter(regex='_GrayVol', axis=1)\n",
    "#data[list(gray_volume)].div(data[' Total cortical gray matter volume (mm3)'], axis=0)\n",
    "\n",
    "#data['Brain_White_Surface_Total_Area'] = data[' R Cortex White Surface Total Area'] + data[' L Cortex White Surface Total Area']\n",
    "#surface_area = data.filter(regex='_SurfArea', axis=1)\n",
    "#data[list(surface_area)].div(data['Brain_White_Surface_Total_Area'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Divide on two dataframes\n",
    "data_woman = data.loc[data['sex'] == \"k\"]\n",
    "data_woman = data_woman.drop(\"sex\", axis =1)\n",
    "data_man = data.loc[data['sex'] == \"m\"]\n",
    "data_man = data_man.drop(\"sex\", axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_woman.columns[data_woman.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#X0 = min_max_scaler.fit_transform(X0)\n",
    "\n",
    "# Normalizing volume as a proportion to total volume\n",
    "\n",
    "\n",
    "# Normalization column-wise\n",
    "data_man_norm = pd.DataFrame(min_max_scaler.fit_transform(data_man), columns=data_man.columns)\n",
    "data_woman_norm = pd.DataFrame(min_max_scaler.fit_transform(data_woman), columns=data_woman.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing volume as a proportion to total volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grupa</th>\n",
       "      <th>Brain Segmentation Volume (mm3)</th>\n",
       "      <th>Brain Segmentation Volume Without Ventricles (mm3)</th>\n",
       "      <th>Brain Segmentation Volume Without Ventricles from Surf (mm3)</th>\n",
       "      <th>Volume of ventricles and choroid plexus (mm3)</th>\n",
       "      <th>Left hemisphere cortical gray matter volume (mm3)</th>\n",
       "      <th>Right hemisphere cortical gray matter volume (mm3)</th>\n",
       "      <th>Total cortical gray matter volume (mm3)</th>\n",
       "      <th>Left hemisphere cerebral white matter volume (mm3)</th>\n",
       "      <th>Right hemisphere cerebral white matter volume (mm3)</th>\n",
       "      <th>...</th>\n",
       "      <th>precentral_MeanCurv</th>\n",
       "      <th>precuneus_MeanCurv</th>\n",
       "      <th>rostralanteriorcingulate_MeanCurv</th>\n",
       "      <th>rostralmiddlefrontal_MeanCurv</th>\n",
       "      <th>superiorfrontal_MeanCurv</th>\n",
       "      <th>superiorparietal_MeanCurv</th>\n",
       "      <th>superiortemporal_MeanCurv</th>\n",
       "      <th>supramarginal_MeanCurv</th>\n",
       "      <th>transversetemporal_MeanCurv</th>\n",
       "      <th>insula_MeanCurv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.463805</td>\n",
       "      <td>0.488626</td>\n",
       "      <td>0.488499</td>\n",
       "      <td>0.157404</td>\n",
       "      <td>0.476402</td>\n",
       "      <td>0.527163</td>\n",
       "      <td>0.501918</td>\n",
       "      <td>0.414785</td>\n",
       "      <td>0.429921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.206720</td>\n",
       "      <td>0.221362</td>\n",
       "      <td>0.220788</td>\n",
       "      <td>0.077157</td>\n",
       "      <td>0.306684</td>\n",
       "      <td>0.332607</td>\n",
       "      <td>0.319715</td>\n",
       "      <td>0.125858</td>\n",
       "      <td>0.143900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.643018</td>\n",
       "      <td>0.683881</td>\n",
       "      <td>0.683447</td>\n",
       "      <td>0.125859</td>\n",
       "      <td>0.670820</td>\n",
       "      <td>0.660590</td>\n",
       "      <td>0.665677</td>\n",
       "      <td>0.625366</td>\n",
       "      <td>0.653354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.135135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.426774</td>\n",
       "      <td>0.449419</td>\n",
       "      <td>0.450038</td>\n",
       "      <td>0.155663</td>\n",
       "      <td>0.417224</td>\n",
       "      <td>0.425398</td>\n",
       "      <td>0.421333</td>\n",
       "      <td>0.420568</td>\n",
       "      <td>0.439521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.180556</td>\n",
       "      <td>0.297297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.731520</td>\n",
       "      <td>0.671023</td>\n",
       "      <td>0.670157</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.637431</td>\n",
       "      <td>0.689993</td>\n",
       "      <td>0.663852</td>\n",
       "      <td>0.463758</td>\n",
       "      <td>0.527107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.473124</td>\n",
       "      <td>0.494444</td>\n",
       "      <td>0.494248</td>\n",
       "      <td>0.193247</td>\n",
       "      <td>0.562698</td>\n",
       "      <td>0.555296</td>\n",
       "      <td>0.558977</td>\n",
       "      <td>0.395379</td>\n",
       "      <td>0.392783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550074</td>\n",
       "      <td>0.583299</td>\n",
       "      <td>0.582700</td>\n",
       "      <td>0.138150</td>\n",
       "      <td>0.565423</td>\n",
       "      <td>0.547309</td>\n",
       "      <td>0.556317</td>\n",
       "      <td>0.519203</td>\n",
       "      <td>0.549278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.243243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.645897</td>\n",
       "      <td>0.674545</td>\n",
       "      <td>0.675712</td>\n",
       "      <td>0.212145</td>\n",
       "      <td>0.716551</td>\n",
       "      <td>0.700477</td>\n",
       "      <td>0.708471</td>\n",
       "      <td>0.561102</td>\n",
       "      <td>0.591807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.648649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.155235</td>\n",
       "      <td>0.153530</td>\n",
       "      <td>0.153277</td>\n",
       "      <td>0.183016</td>\n",
       "      <td>0.078066</td>\n",
       "      <td>0.106095</td>\n",
       "      <td>0.092156</td>\n",
       "      <td>0.181835</td>\n",
       "      <td>0.186692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.621622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.445988</td>\n",
       "      <td>0.480700</td>\n",
       "      <td>0.481209</td>\n",
       "      <td>0.055114</td>\n",
       "      <td>0.507737</td>\n",
       "      <td>0.483545</td>\n",
       "      <td>0.495576</td>\n",
       "      <td>0.441586</td>\n",
       "      <td>0.457009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.351351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452158</td>\n",
       "      <td>0.480579</td>\n",
       "      <td>0.480717</td>\n",
       "      <td>0.112343</td>\n",
       "      <td>0.496282</td>\n",
       "      <td>0.552322</td>\n",
       "      <td>0.524452</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>0.344470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0.448980</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.402778</td>\n",
       "      <td>0.675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.496018</td>\n",
       "      <td>0.510360</td>\n",
       "      <td>0.510089</td>\n",
       "      <td>0.254329</td>\n",
       "      <td>0.363380</td>\n",
       "      <td>0.388700</td>\n",
       "      <td>0.376108</td>\n",
       "      <td>0.537193</td>\n",
       "      <td>0.604681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481802</td>\n",
       "      <td>0.502622</td>\n",
       "      <td>0.502278</td>\n",
       "      <td>0.189375</td>\n",
       "      <td>0.305881</td>\n",
       "      <td>0.332922</td>\n",
       "      <td>0.319474</td>\n",
       "      <td>0.549229</td>\n",
       "      <td>0.606286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.675676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669731</td>\n",
       "      <td>0.704882</td>\n",
       "      <td>0.705935</td>\n",
       "      <td>0.197261</td>\n",
       "      <td>0.582538</td>\n",
       "      <td>0.612126</td>\n",
       "      <td>0.597411</td>\n",
       "      <td>0.623629</td>\n",
       "      <td>0.701333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.459459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370455</td>\n",
       "      <td>0.403040</td>\n",
       "      <td>0.402060</td>\n",
       "      <td>0.028188</td>\n",
       "      <td>0.228670</td>\n",
       "      <td>0.232607</td>\n",
       "      <td>0.230649</td>\n",
       "      <td>0.501223</td>\n",
       "      <td>0.533155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.513514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.610487</td>\n",
       "      <td>0.631910</td>\n",
       "      <td>0.632351</td>\n",
       "      <td>0.273068</td>\n",
       "      <td>0.645679</td>\n",
       "      <td>0.665125</td>\n",
       "      <td>0.655454</td>\n",
       "      <td>0.511013</td>\n",
       "      <td>0.517895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.253219</td>\n",
       "      <td>0.241333</td>\n",
       "      <td>0.241270</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>0.255460</td>\n",
       "      <td>0.289451</td>\n",
       "      <td>0.272546</td>\n",
       "      <td>0.088093</td>\n",
       "      <td>0.099057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.351351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713033</td>\n",
       "      <td>0.760642</td>\n",
       "      <td>0.760547</td>\n",
       "      <td>0.119429</td>\n",
       "      <td>0.718599</td>\n",
       "      <td>0.702116</td>\n",
       "      <td>0.710314</td>\n",
       "      <td>0.727470</td>\n",
       "      <td>0.745413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.216216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.598022</td>\n",
       "      <td>0.650304</td>\n",
       "      <td>0.650058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497807</td>\n",
       "      <td>0.538083</td>\n",
       "      <td>0.518053</td>\n",
       "      <td>0.685992</td>\n",
       "      <td>0.739198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.263889</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.394685</td>\n",
       "      <td>0.424066</td>\n",
       "      <td>0.425114</td>\n",
       "      <td>0.064386</td>\n",
       "      <td>0.437800</td>\n",
       "      <td>0.468257</td>\n",
       "      <td>0.453110</td>\n",
       "      <td>0.329934</td>\n",
       "      <td>0.357431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.265306</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>0.459459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.784840</td>\n",
       "      <td>0.839866</td>\n",
       "      <td>0.839881</td>\n",
       "      <td>0.086784</td>\n",
       "      <td>0.804013</td>\n",
       "      <td>0.810599</td>\n",
       "      <td>0.807324</td>\n",
       "      <td>0.693474</td>\n",
       "      <td>0.750791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.567138</td>\n",
       "      <td>0.567340</td>\n",
       "      <td>0.045559</td>\n",
       "      <td>0.573094</td>\n",
       "      <td>0.602405</td>\n",
       "      <td>0.587828</td>\n",
       "      <td>0.449083</td>\n",
       "      <td>0.497562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.432432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567714</td>\n",
       "      <td>0.600999</td>\n",
       "      <td>0.600638</td>\n",
       "      <td>0.145823</td>\n",
       "      <td>0.595227</td>\n",
       "      <td>0.626270</td>\n",
       "      <td>0.610831</td>\n",
       "      <td>0.477241</td>\n",
       "      <td>0.511502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.216216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.450069</td>\n",
       "      <td>0.459714</td>\n",
       "      <td>0.458226</td>\n",
       "      <td>0.266958</td>\n",
       "      <td>0.231655</td>\n",
       "      <td>0.298229</td>\n",
       "      <td>0.265120</td>\n",
       "      <td>0.455564</td>\n",
       "      <td>0.509918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.945946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299013</td>\n",
       "      <td>0.327077</td>\n",
       "      <td>0.328743</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>0.303664</td>\n",
       "      <td>0.349767</td>\n",
       "      <td>0.326839</td>\n",
       "      <td>0.257376</td>\n",
       "      <td>0.258034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.568782</td>\n",
       "      <td>0.607443</td>\n",
       "      <td>0.607519</td>\n",
       "      <td>0.085842</td>\n",
       "      <td>0.712249</td>\n",
       "      <td>0.752121</td>\n",
       "      <td>0.732292</td>\n",
       "      <td>0.414358</td>\n",
       "      <td>0.450555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.513514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.675126</td>\n",
       "      <td>0.730985</td>\n",
       "      <td>0.730961</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.833506</td>\n",
       "      <td>0.815156</td>\n",
       "      <td>0.579408</td>\n",
       "      <td>0.629747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.297297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583074</td>\n",
       "      <td>0.594662</td>\n",
       "      <td>0.594732</td>\n",
       "      <td>0.323778</td>\n",
       "      <td>0.565438</td>\n",
       "      <td>0.550565</td>\n",
       "      <td>0.557962</td>\n",
       "      <td>0.582394</td>\n",
       "      <td>0.704242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411056</td>\n",
       "      <td>0.416604</td>\n",
       "      <td>0.416208</td>\n",
       "      <td>0.275341</td>\n",
       "      <td>0.398827</td>\n",
       "      <td>0.435872</td>\n",
       "      <td>0.417449</td>\n",
       "      <td>0.371141</td>\n",
       "      <td>0.414276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.189189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.831106</td>\n",
       "      <td>0.861106</td>\n",
       "      <td>0.861128</td>\n",
       "      <td>0.305945</td>\n",
       "      <td>0.868560</td>\n",
       "      <td>0.875130</td>\n",
       "      <td>0.871863</td>\n",
       "      <td>0.769577</td>\n",
       "      <td>0.836781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.189189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.220250</td>\n",
       "      <td>0.247143</td>\n",
       "      <td>0.246874</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.346191</td>\n",
       "      <td>0.348705</td>\n",
       "      <td>0.347441</td>\n",
       "      <td>0.240445</td>\n",
       "      <td>0.211902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.385965</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.301888</td>\n",
       "      <td>0.320233</td>\n",
       "      <td>0.320547</td>\n",
       "      <td>0.076836</td>\n",
       "      <td>0.459881</td>\n",
       "      <td>0.470305</td>\n",
       "      <td>0.465065</td>\n",
       "      <td>0.185235</td>\n",
       "      <td>0.194895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.218045</td>\n",
       "      <td>0.232755</td>\n",
       "      <td>0.233290</td>\n",
       "      <td>0.118163</td>\n",
       "      <td>0.186729</td>\n",
       "      <td>0.255275</td>\n",
       "      <td>0.220818</td>\n",
       "      <td>0.175266</td>\n",
       "      <td>0.251428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>0.435897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.527549</td>\n",
       "      <td>0.540997</td>\n",
       "      <td>0.541044</td>\n",
       "      <td>0.110335</td>\n",
       "      <td>0.679951</td>\n",
       "      <td>0.747153</td>\n",
       "      <td>0.713371</td>\n",
       "      <td>0.339284</td>\n",
       "      <td>0.369542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.282051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636157</td>\n",
       "      <td>0.656494</td>\n",
       "      <td>0.657478</td>\n",
       "      <td>0.044860</td>\n",
       "      <td>0.771277</td>\n",
       "      <td>0.799784</td>\n",
       "      <td>0.785454</td>\n",
       "      <td>0.587248</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.487179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336240</td>\n",
       "      <td>0.343116</td>\n",
       "      <td>0.343008</td>\n",
       "      <td>0.189103</td>\n",
       "      <td>0.403544</td>\n",
       "      <td>0.401077</td>\n",
       "      <td>0.402317</td>\n",
       "      <td>0.279428</td>\n",
       "      <td>0.268727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315616</td>\n",
       "      <td>0.333390</td>\n",
       "      <td>0.333343</td>\n",
       "      <td>0.082946</td>\n",
       "      <td>0.495282</td>\n",
       "      <td>0.539672</td>\n",
       "      <td>0.517358</td>\n",
       "      <td>0.199644</td>\n",
       "      <td>0.228664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481358</td>\n",
       "      <td>0.502989</td>\n",
       "      <td>0.502443</td>\n",
       "      <td>0.048179</td>\n",
       "      <td>0.397998</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.439949</td>\n",
       "      <td>0.456329</td>\n",
       "      <td>0.485412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.435897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.793561</td>\n",
       "      <td>0.805254</td>\n",
       "      <td>0.805707</td>\n",
       "      <td>0.113360</td>\n",
       "      <td>0.911484</td>\n",
       "      <td>0.968015</td>\n",
       "      <td>0.939597</td>\n",
       "      <td>0.644415</td>\n",
       "      <td>0.673224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469906</td>\n",
       "      <td>0.487973</td>\n",
       "      <td>0.487825</td>\n",
       "      <td>0.068188</td>\n",
       "      <td>0.588222</td>\n",
       "      <td>0.649268</td>\n",
       "      <td>0.618581</td>\n",
       "      <td>0.304833</td>\n",
       "      <td>0.306288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.480348</td>\n",
       "      <td>0.494306</td>\n",
       "      <td>0.494067</td>\n",
       "      <td>0.124527</td>\n",
       "      <td>0.446950</td>\n",
       "      <td>0.454332</td>\n",
       "      <td>0.450621</td>\n",
       "      <td>0.519072</td>\n",
       "      <td>0.518834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.435897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302411</td>\n",
       "      <td>0.304414</td>\n",
       "      <td>0.304536</td>\n",
       "      <td>0.232167</td>\n",
       "      <td>0.287049</td>\n",
       "      <td>0.290968</td>\n",
       "      <td>0.288998</td>\n",
       "      <td>0.336683</td>\n",
       "      <td>0.323753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.410256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.320828</td>\n",
       "      <td>0.338228</td>\n",
       "      <td>0.337999</td>\n",
       "      <td>0.092551</td>\n",
       "      <td>0.313243</td>\n",
       "      <td>0.316951</td>\n",
       "      <td>0.315087</td>\n",
       "      <td>0.335395</td>\n",
       "      <td>0.328645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375417</td>\n",
       "      <td>0.397836</td>\n",
       "      <td>0.397519</td>\n",
       "      <td>0.041561</td>\n",
       "      <td>0.516546</td>\n",
       "      <td>0.512820</td>\n",
       "      <td>0.514693</td>\n",
       "      <td>0.323584</td>\n",
       "      <td>0.303408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.743590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.720237</td>\n",
       "      <td>0.718081</td>\n",
       "      <td>0.718607</td>\n",
       "      <td>0.262211</td>\n",
       "      <td>0.691866</td>\n",
       "      <td>0.701245</td>\n",
       "      <td>0.696530</td>\n",
       "      <td>0.798389</td>\n",
       "      <td>0.783572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721507</td>\n",
       "      <td>0.725244</td>\n",
       "      <td>0.725462</td>\n",
       "      <td>0.217097</td>\n",
       "      <td>0.491440</td>\n",
       "      <td>0.540610</td>\n",
       "      <td>0.515893</td>\n",
       "      <td>0.796709</td>\n",
       "      <td>0.824806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620045</td>\n",
       "      <td>0.567274</td>\n",
       "      <td>0.567610</td>\n",
       "      <td>0.741030</td>\n",
       "      <td>0.639813</td>\n",
       "      <td>0.679869</td>\n",
       "      <td>0.659733</td>\n",
       "      <td>0.472463</td>\n",
       "      <td>0.492275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.245614</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.246753</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.581279</td>\n",
       "      <td>0.595297</td>\n",
       "      <td>0.595123</td>\n",
       "      <td>0.111350</td>\n",
       "      <td>0.640532</td>\n",
       "      <td>0.669862</td>\n",
       "      <td>0.655118</td>\n",
       "      <td>0.535871</td>\n",
       "      <td>0.535415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.379671</td>\n",
       "      <td>0.393281</td>\n",
       "      <td>0.393752</td>\n",
       "      <td>0.127494</td>\n",
       "      <td>0.374925</td>\n",
       "      <td>0.397272</td>\n",
       "      <td>0.386038</td>\n",
       "      <td>0.426805</td>\n",
       "      <td>0.443562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.435897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.519574</td>\n",
       "      <td>0.522490</td>\n",
       "      <td>0.522066</td>\n",
       "      <td>0.212568</td>\n",
       "      <td>0.499444</td>\n",
       "      <td>0.492906</td>\n",
       "      <td>0.496193</td>\n",
       "      <td>0.575572</td>\n",
       "      <td>0.577303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.493506</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.572496</td>\n",
       "      <td>0.552564</td>\n",
       "      <td>0.552410</td>\n",
       "      <td>0.424980</td>\n",
       "      <td>0.557113</td>\n",
       "      <td>0.594037</td>\n",
       "      <td>0.575475</td>\n",
       "      <td>0.443792</td>\n",
       "      <td>0.442323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385567</td>\n",
       "      <td>0.404182</td>\n",
       "      <td>0.404640</td>\n",
       "      <td>0.076992</td>\n",
       "      <td>0.554315</td>\n",
       "      <td>0.561930</td>\n",
       "      <td>0.558102</td>\n",
       "      <td>0.278320</td>\n",
       "      <td>0.285665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.376623</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.132289</td>\n",
       "      <td>0.139552</td>\n",
       "      <td>0.139960</td>\n",
       "      <td>0.201597</td>\n",
       "      <td>0.251198</td>\n",
       "      <td>0.241626</td>\n",
       "      <td>0.246438</td>\n",
       "      <td>0.032515</td>\n",
       "      <td>0.032315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.476090</td>\n",
       "      <td>0.494909</td>\n",
       "      <td>0.495160</td>\n",
       "      <td>0.065377</td>\n",
       "      <td>0.437249</td>\n",
       "      <td>0.463271</td>\n",
       "      <td>0.450190</td>\n",
       "      <td>0.500658</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.410256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.411665</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>0.433421</td>\n",
       "      <td>0.038887</td>\n",
       "      <td>0.447943</td>\n",
       "      <td>0.483690</td>\n",
       "      <td>0.465721</td>\n",
       "      <td>0.349024</td>\n",
       "      <td>0.364473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.371327</td>\n",
       "      <td>0.346609</td>\n",
       "      <td>0.347154</td>\n",
       "      <td>0.493168</td>\n",
       "      <td>0.427169</td>\n",
       "      <td>0.442858</td>\n",
       "      <td>0.434971</td>\n",
       "      <td>0.302587</td>\n",
       "      <td>0.306174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.537659</td>\n",
       "      <td>0.549391</td>\n",
       "      <td>0.550351</td>\n",
       "      <td>0.143326</td>\n",
       "      <td>0.567639</td>\n",
       "      <td>0.597862</td>\n",
       "      <td>0.582669</td>\n",
       "      <td>0.527739</td>\n",
       "      <td>0.521631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.581790</td>\n",
       "      <td>0.582206</td>\n",
       "      <td>0.582261</td>\n",
       "      <td>0.230742</td>\n",
       "      <td>0.672243</td>\n",
       "      <td>0.669661</td>\n",
       "      <td>0.670959</td>\n",
       "      <td>0.396094</td>\n",
       "      <td>0.388620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.749121</td>\n",
       "      <td>0.732903</td>\n",
       "      <td>0.732617</td>\n",
       "      <td>0.409167</td>\n",
       "      <td>0.657287</td>\n",
       "      <td>0.692990</td>\n",
       "      <td>0.675042</td>\n",
       "      <td>0.717750</td>\n",
       "      <td>0.703190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.532468</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321695</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.348712</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0.387535</td>\n",
       "      <td>0.407347</td>\n",
       "      <td>0.397388</td>\n",
       "      <td>0.345383</td>\n",
       "      <td>0.366534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>487 rows  318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     grupa   Brain Segmentation Volume (mm3)  \\\n",
       "0      1.0                          0.463805   \n",
       "1      1.0                          0.206720   \n",
       "2      1.0                          0.643018   \n",
       "3      0.0                          0.426774   \n",
       "4      0.0                          0.731520   \n",
       "5      1.0                          0.473124   \n",
       "6      0.0                          0.550074   \n",
       "7      0.0                          0.645897   \n",
       "8      1.0                          0.155235   \n",
       "9      0.0                          0.445988   \n",
       "10     0.0                          0.452158   \n",
       "11     1.0                          0.496018   \n",
       "12     0.0                          0.481802   \n",
       "13     0.0                          0.669731   \n",
       "14     0.0                          0.370455   \n",
       "15     0.0                          0.610487   \n",
       "16     1.0                          0.253219   \n",
       "17     0.0                          0.713033   \n",
       "18     0.0                          0.598022   \n",
       "19     0.0                          0.394685   \n",
       "20     1.0                          0.784840   \n",
       "21     1.0                          0.523700   \n",
       "22     0.0                          0.567714   \n",
       "23     0.0                          0.450069   \n",
       "24     0.0                          0.299013   \n",
       "25     0.0                          0.568782   \n",
       "26     0.0                          0.675126   \n",
       "27     0.0                          0.583074   \n",
       "28     0.0                          0.411056   \n",
       "29     1.0                          0.831106   \n",
       "..     ...                               ...   \n",
       "457    1.0                          0.220250   \n",
       "458    1.0                          0.301888   \n",
       "459    1.0                          0.218045   \n",
       "460    1.0                          0.527549   \n",
       "461    1.0                          0.636157   \n",
       "462    0.0                          0.336240   \n",
       "463    0.0                          0.315616   \n",
       "464    0.0                          0.481358   \n",
       "465    0.0                          0.793561   \n",
       "466    0.0                          0.469906   \n",
       "467    1.0                          0.480348   \n",
       "468    0.0                          0.302411   \n",
       "469    1.0                          0.320828   \n",
       "470    0.0                          0.375417   \n",
       "471    1.0                          0.720237   \n",
       "472    0.0                          0.721507   \n",
       "473    0.0                          0.620045   \n",
       "474    0.0                          0.581279   \n",
       "475    1.0                          0.379671   \n",
       "476    1.0                          0.519574   \n",
       "477    1.0                          0.572496   \n",
       "478    0.0                          0.385567   \n",
       "479    1.0                          0.132289   \n",
       "480    1.0                          0.476090   \n",
       "481    1.0                          0.411665   \n",
       "482    1.0                          0.371327   \n",
       "483    1.0                          0.537659   \n",
       "484    1.0                          0.581790   \n",
       "485    0.0                          0.749121   \n",
       "486    1.0                          0.321695   \n",
       "\n",
       "      Brain Segmentation Volume Without Ventricles (mm3)  \\\n",
       "0                                             0.488626     \n",
       "1                                             0.221362     \n",
       "2                                             0.683881     \n",
       "3                                             0.449419     \n",
       "4                                             0.671023     \n",
       "5                                             0.494444     \n",
       "6                                             0.583299     \n",
       "7                                             0.674545     \n",
       "8                                             0.153530     \n",
       "9                                             0.480700     \n",
       "10                                            0.480579     \n",
       "11                                            0.510360     \n",
       "12                                            0.502622     \n",
       "13                                            0.704882     \n",
       "14                                            0.403040     \n",
       "15                                            0.631910     \n",
       "16                                            0.241333     \n",
       "17                                            0.760642     \n",
       "18                                            0.650304     \n",
       "19                                            0.424066     \n",
       "20                                            0.839866     \n",
       "21                                            0.567138     \n",
       "22                                            0.600999     \n",
       "23                                            0.459714     \n",
       "24                                            0.327077     \n",
       "25                                            0.607443     \n",
       "26                                            0.730985     \n",
       "27                                            0.594662     \n",
       "28                                            0.416604     \n",
       "29                                            0.861106     \n",
       "..                                                 ...     \n",
       "457                                           0.247143     \n",
       "458                                           0.320233     \n",
       "459                                           0.232755     \n",
       "460                                           0.540997     \n",
       "461                                           0.656494     \n",
       "462                                           0.343116     \n",
       "463                                           0.333390     \n",
       "464                                           0.502989     \n",
       "465                                           0.805254     \n",
       "466                                           0.487973     \n",
       "467                                           0.494306     \n",
       "468                                           0.304414     \n",
       "469                                           0.338228     \n",
       "470                                           0.397836     \n",
       "471                                           0.718081     \n",
       "472                                           0.725244     \n",
       "473                                           0.567274     \n",
       "474                                           0.595297     \n",
       "475                                           0.393281     \n",
       "476                                           0.522490     \n",
       "477                                           0.552564     \n",
       "478                                           0.404182     \n",
       "479                                           0.139552     \n",
       "480                                           0.494909     \n",
       "481                                           0.433721     \n",
       "482                                           0.346609     \n",
       "483                                           0.549391     \n",
       "484                                           0.582206     \n",
       "485                                           0.732903     \n",
       "486                                           0.348214     \n",
       "\n",
       "      Brain Segmentation Volume Without Ventricles from Surf (mm3)  \\\n",
       "0                                             0.488499               \n",
       "1                                             0.220788               \n",
       "2                                             0.683447               \n",
       "3                                             0.450038               \n",
       "4                                             0.670157               \n",
       "5                                             0.494248               \n",
       "6                                             0.582700               \n",
       "7                                             0.675712               \n",
       "8                                             0.153277               \n",
       "9                                             0.481209               \n",
       "10                                            0.480717               \n",
       "11                                            0.510089               \n",
       "12                                            0.502278               \n",
       "13                                            0.705935               \n",
       "14                                            0.402060               \n",
       "15                                            0.632351               \n",
       "16                                            0.241270               \n",
       "17                                            0.760547               \n",
       "18                                            0.650058               \n",
       "19                                            0.425114               \n",
       "20                                            0.839881               \n",
       "21                                            0.567340               \n",
       "22                                            0.600638               \n",
       "23                                            0.458226               \n",
       "24                                            0.328743               \n",
       "25                                            0.607519               \n",
       "26                                            0.730961               \n",
       "27                                            0.594732               \n",
       "28                                            0.416208               \n",
       "29                                            0.861128               \n",
       "..                                                 ...               \n",
       "457                                           0.246874               \n",
       "458                                           0.320547               \n",
       "459                                           0.233290               \n",
       "460                                           0.541044               \n",
       "461                                           0.657478               \n",
       "462                                           0.343008               \n",
       "463                                           0.333343               \n",
       "464                                           0.502443               \n",
       "465                                           0.805707               \n",
       "466                                           0.487825               \n",
       "467                                           0.494067               \n",
       "468                                           0.304536               \n",
       "469                                           0.337999               \n",
       "470                                           0.397519               \n",
       "471                                           0.718607               \n",
       "472                                           0.725462               \n",
       "473                                           0.567610               \n",
       "474                                           0.595123               \n",
       "475                                           0.393752               \n",
       "476                                           0.522066               \n",
       "477                                           0.552410               \n",
       "478                                           0.404640               \n",
       "479                                           0.139960               \n",
       "480                                           0.495160               \n",
       "481                                           0.433421               \n",
       "482                                           0.347154               \n",
       "483                                           0.550351               \n",
       "484                                           0.582261               \n",
       "485                                           0.732617               \n",
       "486                                           0.348712               \n",
       "\n",
       "      Volume of ventricles and choroid plexus (mm3)  \\\n",
       "0                                          0.157404   \n",
       "1                                          0.077157   \n",
       "2                                          0.125859   \n",
       "3                                          0.155663   \n",
       "4                                          1.000000   \n",
       "5                                          0.193247   \n",
       "6                                          0.138150   \n",
       "7                                          0.212145   \n",
       "8                                          0.183016   \n",
       "9                                          0.055114   \n",
       "10                                         0.112343   \n",
       "11                                         0.254329   \n",
       "12                                         0.189375   \n",
       "13                                         0.197261   \n",
       "14                                         0.028188   \n",
       "15                                         0.273068   \n",
       "16                                         0.299000   \n",
       "17                                         0.119429   \n",
       "18                                         0.000000   \n",
       "19                                         0.064386   \n",
       "20                                         0.086784   \n",
       "21                                         0.045559   \n",
       "22                                         0.145823   \n",
       "23                                         0.266958   \n",
       "24                                         0.006412   \n",
       "25                                         0.085842   \n",
       "26                                         0.041527   \n",
       "27                                         0.323778   \n",
       "28                                         0.275341   \n",
       "29                                         0.305945   \n",
       "..                                              ...   \n",
       "457                                        0.002089   \n",
       "458                                        0.076836   \n",
       "459                                        0.118163   \n",
       "460                                        0.110335   \n",
       "461                                        0.044860   \n",
       "462                                        0.189103   \n",
       "463                                        0.082946   \n",
       "464                                        0.048179   \n",
       "465                                        0.113360   \n",
       "466                                        0.068188   \n",
       "467                                        0.124527   \n",
       "468                                        0.232167   \n",
       "469                                        0.092551   \n",
       "470                                        0.041561   \n",
       "471                                        0.262211   \n",
       "472                                        0.217097   \n",
       "473                                        0.741030   \n",
       "474                                        0.111350   \n",
       "475                                        0.127494   \n",
       "476                                        0.212568   \n",
       "477                                        0.424980   \n",
       "478                                        0.076992   \n",
       "479                                        0.201597   \n",
       "480                                        0.065377   \n",
       "481                                        0.038887   \n",
       "482                                        0.493168   \n",
       "483                                        0.143326   \n",
       "484                                        0.230742   \n",
       "485                                        0.409167   \n",
       "486                                        0.004412   \n",
       "\n",
       "      Left hemisphere cortical gray matter volume (mm3)  \\\n",
       "0                                             0.476402    \n",
       "1                                             0.306684    \n",
       "2                                             0.670820    \n",
       "3                                             0.417224    \n",
       "4                                             0.637431    \n",
       "5                                             0.562698    \n",
       "6                                             0.565423    \n",
       "7                                             0.716551    \n",
       "8                                             0.078066    \n",
       "9                                             0.507737    \n",
       "10                                            0.496282    \n",
       "11                                            0.363380    \n",
       "12                                            0.305881    \n",
       "13                                            0.582538    \n",
       "14                                            0.228670    \n",
       "15                                            0.645679    \n",
       "16                                            0.255460    \n",
       "17                                            0.718599    \n",
       "18                                            0.497807    \n",
       "19                                            0.437800    \n",
       "20                                            0.804013    \n",
       "21                                            0.573094    \n",
       "22                                            0.595227    \n",
       "23                                            0.231655    \n",
       "24                                            0.303664    \n",
       "25                                            0.712249    \n",
       "26                                            0.796610    \n",
       "27                                            0.565438    \n",
       "28                                            0.398827    \n",
       "29                                            0.868560    \n",
       "..                                                 ...    \n",
       "457                                           0.346191    \n",
       "458                                           0.459881    \n",
       "459                                           0.186729    \n",
       "460                                           0.679951    \n",
       "461                                           0.771277    \n",
       "462                                           0.403544    \n",
       "463                                           0.495282    \n",
       "464                                           0.397998    \n",
       "465                                           0.911484    \n",
       "466                                           0.588222    \n",
       "467                                           0.446950    \n",
       "468                                           0.287049    \n",
       "469                                           0.313243    \n",
       "470                                           0.516546    \n",
       "471                                           0.691866    \n",
       "472                                           0.491440    \n",
       "473                                           0.639813    \n",
       "474                                           0.640532    \n",
       "475                                           0.374925    \n",
       "476                                           0.499444    \n",
       "477                                           0.557113    \n",
       "478                                           0.554315    \n",
       "479                                           0.251198    \n",
       "480                                           0.437249    \n",
       "481                                           0.447943    \n",
       "482                                           0.427169    \n",
       "483                                           0.567639    \n",
       "484                                           0.672243    \n",
       "485                                           0.657287    \n",
       "486                                           0.387535    \n",
       "\n",
       "      Right hemisphere cortical gray matter volume (mm3)  \\\n",
       "0                                             0.527163     \n",
       "1                                             0.332607     \n",
       "2                                             0.660590     \n",
       "3                                             0.425398     \n",
       "4                                             0.689993     \n",
       "5                                             0.555296     \n",
       "6                                             0.547309     \n",
       "7                                             0.700477     \n",
       "8                                             0.106095     \n",
       "9                                             0.483545     \n",
       "10                                            0.552322     \n",
       "11                                            0.388700     \n",
       "12                                            0.332922     \n",
       "13                                            0.612126     \n",
       "14                                            0.232607     \n",
       "15                                            0.665125     \n",
       "16                                            0.289451     \n",
       "17                                            0.702116     \n",
       "18                                            0.538083     \n",
       "19                                            0.468257     \n",
       "20                                            0.810599     \n",
       "21                                            0.602405     \n",
       "22                                            0.626270     \n",
       "23                                            0.298229     \n",
       "24                                            0.349767     \n",
       "25                                            0.752121     \n",
       "26                                            0.833506     \n",
       "27                                            0.550565     \n",
       "28                                            0.435872     \n",
       "29                                            0.875130     \n",
       "..                                                 ...     \n",
       "457                                           0.348705     \n",
       "458                                           0.470305     \n",
       "459                                           0.255275     \n",
       "460                                           0.747153     \n",
       "461                                           0.799784     \n",
       "462                                           0.401077     \n",
       "463                                           0.539672     \n",
       "464                                           0.482353     \n",
       "465                                           0.968015     \n",
       "466                                           0.649268     \n",
       "467                                           0.454332     \n",
       "468                                           0.290968     \n",
       "469                                           0.316951     \n",
       "470                                           0.512820     \n",
       "471                                           0.701245     \n",
       "472                                           0.540610     \n",
       "473                                           0.679869     \n",
       "474                                           0.669862     \n",
       "475                                           0.397272     \n",
       "476                                           0.492906     \n",
       "477                                           0.594037     \n",
       "478                                           0.561930     \n",
       "479                                           0.241626     \n",
       "480                                           0.463271     \n",
       "481                                           0.483690     \n",
       "482                                           0.442858     \n",
       "483                                           0.597862     \n",
       "484                                           0.669661     \n",
       "485                                           0.692990     \n",
       "486                                           0.407347     \n",
       "\n",
       "      Total cortical gray matter volume (mm3)  \\\n",
       "0                                    0.501918   \n",
       "1                                    0.319715   \n",
       "2                                    0.665677   \n",
       "3                                    0.421333   \n",
       "4                                    0.663852   \n",
       "5                                    0.558977   \n",
       "6                                    0.556317   \n",
       "7                                    0.708471   \n",
       "8                                    0.092156   \n",
       "9                                    0.495576   \n",
       "10                                   0.524452   \n",
       "11                                   0.376108   \n",
       "12                                   0.319474   \n",
       "13                                   0.597411   \n",
       "14                                   0.230649   \n",
       "15                                   0.655454   \n",
       "16                                   0.272546   \n",
       "17                                   0.710314   \n",
       "18                                   0.518053   \n",
       "19                                   0.453110   \n",
       "20                                   0.807324   \n",
       "21                                   0.587828   \n",
       "22                                   0.610831   \n",
       "23                                   0.265120   \n",
       "24                                   0.326839   \n",
       "25                                   0.732292   \n",
       "26                                   0.815156   \n",
       "27                                   0.557962   \n",
       "28                                   0.417449   \n",
       "29                                   0.871863   \n",
       "..                                        ...   \n",
       "457                                  0.347441   \n",
       "458                                  0.465065   \n",
       "459                                  0.220818   \n",
       "460                                  0.713371   \n",
       "461                                  0.785454   \n",
       "462                                  0.402317   \n",
       "463                                  0.517358   \n",
       "464                                  0.439949   \n",
       "465                                  0.939597   \n",
       "466                                  0.618581   \n",
       "467                                  0.450621   \n",
       "468                                  0.288998   \n",
       "469                                  0.315087   \n",
       "470                                  0.514693   \n",
       "471                                  0.696530   \n",
       "472                                  0.515893   \n",
       "473                                  0.659733   \n",
       "474                                  0.655118   \n",
       "475                                  0.386038   \n",
       "476                                  0.496193   \n",
       "477                                  0.575475   \n",
       "478                                  0.558102   \n",
       "479                                  0.246438   \n",
       "480                                  0.450190   \n",
       "481                                  0.465721   \n",
       "482                                  0.434971   \n",
       "483                                  0.582669   \n",
       "484                                  0.670959   \n",
       "485                                  0.675042   \n",
       "486                                  0.397388   \n",
       "\n",
       "      Left hemisphere cerebral white matter volume (mm3)  \\\n",
       "0                                             0.414785     \n",
       "1                                             0.125858     \n",
       "2                                             0.625366     \n",
       "3                                             0.420568     \n",
       "4                                             0.463758     \n",
       "5                                             0.395379     \n",
       "6                                             0.519203     \n",
       "7                                             0.561102     \n",
       "8                                             0.181835     \n",
       "9                                             0.441586     \n",
       "10                                            0.322034     \n",
       "11                                            0.537193     \n",
       "12                                            0.549229     \n",
       "13                                            0.623629     \n",
       "14                                            0.501223     \n",
       "15                                            0.511013     \n",
       "16                                            0.088093     \n",
       "17                                            0.727470     \n",
       "18                                            0.685992     \n",
       "19                                            0.329934     \n",
       "20                                            0.693474     \n",
       "21                                            0.449083     \n",
       "22                                            0.477241     \n",
       "23                                            0.455564     \n",
       "24                                            0.257376     \n",
       "25                                            0.414358     \n",
       "26                                            0.579408     \n",
       "27                                            0.582394     \n",
       "28                                            0.371141     \n",
       "29                                            0.769577     \n",
       "..                                                 ...     \n",
       "457                                           0.240445     \n",
       "458                                           0.185235     \n",
       "459                                           0.175266     \n",
       "460                                           0.339284     \n",
       "461                                           0.587248     \n",
       "462                                           0.279428     \n",
       "463                                           0.199644     \n",
       "464                                           0.456329     \n",
       "465                                           0.644415     \n",
       "466                                           0.304833     \n",
       "467                                           0.519072     \n",
       "468                                           0.336683     \n",
       "469                                           0.335395     \n",
       "470                                           0.323584     \n",
       "471                                           0.798389     \n",
       "472                                           0.796709     \n",
       "473                                           0.472463     \n",
       "474                                           0.535871     \n",
       "475                                           0.426805     \n",
       "476                                           0.575572     \n",
       "477                                           0.443792     \n",
       "478                                           0.278320     \n",
       "479                                           0.032515     \n",
       "480                                           0.500658     \n",
       "481                                           0.349024     \n",
       "482                                           0.302587     \n",
       "483                                           0.527739     \n",
       "484                                           0.396094     \n",
       "485                                           0.717750     \n",
       "486                                           0.345383     \n",
       "\n",
       "      Right hemisphere cerebral white matter volume (mm3)       ...         \\\n",
       "0                                             0.429921          ...          \n",
       "1                                             0.143900          ...          \n",
       "2                                             0.653354          ...          \n",
       "3                                             0.439521          ...          \n",
       "4                                             0.527107          ...          \n",
       "5                                             0.392783          ...          \n",
       "6                                             0.549278          ...          \n",
       "7                                             0.591807          ...          \n",
       "8                                             0.186692          ...          \n",
       "9                                             0.457009          ...          \n",
       "10                                            0.344470          ...          \n",
       "11                                            0.604681          ...          \n",
       "12                                            0.606286          ...          \n",
       "13                                            0.701333          ...          \n",
       "14                                            0.533155          ...          \n",
       "15                                            0.517895          ...          \n",
       "16                                            0.099057          ...          \n",
       "17                                            0.745413          ...          \n",
       "18                                            0.739198          ...          \n",
       "19                                            0.357431          ...          \n",
       "20                                            0.750791          ...          \n",
       "21                                            0.497562          ...          \n",
       "22                                            0.511502          ...          \n",
       "23                                            0.509918          ...          \n",
       "24                                            0.258034          ...          \n",
       "25                                            0.450555          ...          \n",
       "26                                            0.629747          ...          \n",
       "27                                            0.704242          ...          \n",
       "28                                            0.414276          ...          \n",
       "29                                            0.836781          ...          \n",
       "..                                                 ...          ...          \n",
       "457                                           0.211902          ...          \n",
       "458                                           0.194895          ...          \n",
       "459                                           0.251428          ...          \n",
       "460                                           0.369542          ...          \n",
       "461                                           0.602167          ...          \n",
       "462                                           0.268727          ...          \n",
       "463                                           0.228664          ...          \n",
       "464                                           0.485412          ...          \n",
       "465                                           0.673224          ...          \n",
       "466                                           0.306288          ...          \n",
       "467                                           0.518834          ...          \n",
       "468                                           0.323753          ...          \n",
       "469                                           0.328645          ...          \n",
       "470                                           0.303408          ...          \n",
       "471                                           0.783572          ...          \n",
       "472                                           0.824806          ...          \n",
       "473                                           0.492275          ...          \n",
       "474                                           0.535415          ...          \n",
       "475                                           0.443562          ...          \n",
       "476                                           0.577303          ...          \n",
       "477                                           0.442323          ...          \n",
       "478                                           0.285665          ...          \n",
       "479                                           0.032315          ...          \n",
       "480                                           0.507812          ...          \n",
       "481                                           0.364473          ...          \n",
       "482                                           0.306174          ...          \n",
       "483                                           0.521631          ...          \n",
       "484                                           0.388620          ...          \n",
       "485                                           0.703190          ...          \n",
       "486                                           0.366534          ...          \n",
       "\n",
       "     precentral_MeanCurv  precuneus_MeanCurv  \\\n",
       "0               0.600000            0.348837   \n",
       "1               0.422222            0.627907   \n",
       "2               0.355556            0.558140   \n",
       "3               0.600000            0.348837   \n",
       "4               0.422222            0.488372   \n",
       "5               0.377778            0.372093   \n",
       "6               0.266667            0.441860   \n",
       "7               0.444444            0.488372   \n",
       "8               0.311111            0.348837   \n",
       "9               0.555556            0.604651   \n",
       "10              0.400000            0.651163   \n",
       "11              0.355556            0.465116   \n",
       "12              0.400000            0.534884   \n",
       "13              0.333333            0.441860   \n",
       "14              0.577778            0.441860   \n",
       "15              0.377778            0.558140   \n",
       "16              0.266667            0.348837   \n",
       "17              0.422222            0.697674   \n",
       "18              0.377778            0.232558   \n",
       "19              0.488889            0.534884   \n",
       "20              0.400000            0.790698   \n",
       "21              0.266667            0.744186   \n",
       "22              0.222222            0.465116   \n",
       "23              0.777778            0.395349   \n",
       "24              0.488889            0.488372   \n",
       "25              0.288889            0.372093   \n",
       "26              0.266667            0.441860   \n",
       "27              0.244444            0.395349   \n",
       "28              0.155556            0.418605   \n",
       "29              0.266667            0.418605   \n",
       "..                   ...                 ...   \n",
       "457             0.368421            0.714286   \n",
       "458             0.342105            0.542857   \n",
       "459             0.657895            0.571429   \n",
       "460             0.315789            0.542857   \n",
       "461             0.342105            0.371429   \n",
       "462             0.657895            0.771429   \n",
       "463             0.394737            0.457143   \n",
       "464             0.578947            0.542857   \n",
       "465             0.447368            0.600000   \n",
       "466             0.368421            0.257143   \n",
       "467             0.447368            0.342857   \n",
       "468             0.210526            0.285714   \n",
       "469             0.578947            0.628571   \n",
       "470             0.605263            0.485714   \n",
       "471             0.315789            0.514286   \n",
       "472             0.552632            0.600000   \n",
       "473             0.526316            0.485714   \n",
       "474             0.263158            0.314286   \n",
       "475             0.210526            0.428571   \n",
       "476             0.526316            0.457143   \n",
       "477             0.368421            0.542857   \n",
       "478             0.500000            0.228571   \n",
       "479             0.894737            0.885714   \n",
       "480             0.684211            0.857143   \n",
       "481             0.500000            0.457143   \n",
       "482             0.500000            0.771429   \n",
       "483             0.421053            0.371429   \n",
       "484             0.184211            0.142857   \n",
       "485             0.473684            0.542857   \n",
       "486             0.684211            0.314286   \n",
       "\n",
       "     rostralanteriorcingulate_MeanCurv  rostralmiddlefrontal_MeanCurv  \\\n",
       "0                             0.285714                       0.466667   \n",
       "1                             0.571429                       0.733333   \n",
       "2                             0.346939                       0.566667   \n",
       "3                             0.551020                       0.700000   \n",
       "4                             0.510204                       0.233333   \n",
       "5                             0.265306                       0.400000   \n",
       "6                             0.285714                       0.366667   \n",
       "7                             0.530612                       0.333333   \n",
       "8                             0.469388                       0.600000   \n",
       "9                             0.102041                       0.433333   \n",
       "10                            0.448980                       0.566667   \n",
       "11                            0.367347                       0.266667   \n",
       "12                            0.510204                       0.333333   \n",
       "13                            0.224490                       0.166667   \n",
       "14                            0.653061                       0.566667   \n",
       "15                            0.265306                       0.133333   \n",
       "16                            0.367347                       0.033333   \n",
       "17                            0.204082                       0.600000   \n",
       "18                            0.061224                       0.000000   \n",
       "19                            0.265306                       0.600000   \n",
       "20                            0.367347                       0.566667   \n",
       "21                            0.489796                       0.366667   \n",
       "22                            0.510204                       0.266667   \n",
       "23                            0.408163                       1.000000   \n",
       "24                            0.489796                       0.533333   \n",
       "25                            0.489796                       0.333333   \n",
       "26                            0.224490                       0.233333   \n",
       "27                            0.142857                       0.300000   \n",
       "28                            0.653061                       0.200000   \n",
       "29                            0.367347                       0.133333   \n",
       "..                                 ...                            ...   \n",
       "457                           0.385965                       0.594595   \n",
       "458                           0.403509                       0.810811   \n",
       "459                           0.403509                       0.567568   \n",
       "460                           0.473684                       0.378378   \n",
       "461                           0.192982                       0.108108   \n",
       "462                           0.701754                       0.729730   \n",
       "463                           0.263158                       0.351351   \n",
       "464                           0.421053                       0.432432   \n",
       "465                           0.368421                       0.243243   \n",
       "466                           0.438596                       0.432432   \n",
       "467                           0.210526                       0.270270   \n",
       "468                           0.228070                       0.189189   \n",
       "469                           0.368421                       0.540541   \n",
       "470                           0.368421                       0.675676   \n",
       "471                           0.298246                       0.297297   \n",
       "472                           0.280702                       0.648649   \n",
       "473                           0.245614                       0.675676   \n",
       "474                           0.526316                       0.486486   \n",
       "475                           0.561404                       0.405405   \n",
       "476                           0.298246                       1.000000   \n",
       "477                           0.666667                       0.540541   \n",
       "478                           0.438596                       0.621622   \n",
       "479                           0.649123                       0.783784   \n",
       "480                           0.666667                       0.594595   \n",
       "481                           0.315789                       0.675676   \n",
       "482                           0.614035                       0.594595   \n",
       "483                           0.403509                       0.594595   \n",
       "484                           0.228070                       0.081081   \n",
       "485                           0.456140                       0.513514   \n",
       "486                           0.456140                       0.540541   \n",
       "\n",
       "     superiorfrontal_MeanCurv  superiorparietal_MeanCurv  \\\n",
       "0                    0.520000                   0.500000   \n",
       "1                    0.520000                   0.531250   \n",
       "2                    0.600000                   0.468750   \n",
       "3                    0.600000                   0.468750   \n",
       "4                    0.200000                   0.406250   \n",
       "5                    0.160000                   0.187500   \n",
       "6                    0.280000                   0.281250   \n",
       "7                    0.240000                   0.593750   \n",
       "8                    0.320000                   0.500000   \n",
       "9                    0.320000                   0.468750   \n",
       "10                   0.360000                   0.375000   \n",
       "11                   0.080000                   0.500000   \n",
       "12                   0.360000                   0.531250   \n",
       "13                   0.120000                   0.156250   \n",
       "14                   0.320000                   0.437500   \n",
       "15                   0.480000                   0.468750   \n",
       "16                   0.120000                   0.187500   \n",
       "17                   0.320000                   0.812500   \n",
       "18                   0.120000                   0.281250   \n",
       "19                   0.440000                   0.000000   \n",
       "20                   0.560000                   0.218750   \n",
       "21                   0.080000                   0.406250   \n",
       "22                   0.280000                   0.281250   \n",
       "23                   0.600000                   0.406250   \n",
       "24                   0.600000                   0.281250   \n",
       "25                   0.240000                   0.218750   \n",
       "26                   0.080000                   0.250000   \n",
       "27                   0.280000                   0.312500   \n",
       "28                   0.240000                   0.437500   \n",
       "29                   0.360000                   0.187500   \n",
       "..                        ...                        ...   \n",
       "457                  0.629630                   0.529412   \n",
       "458                  0.555556                   0.529412   \n",
       "459                  0.444444                   0.588235   \n",
       "460                  0.333333                   0.117647   \n",
       "461                  0.111111                   0.617647   \n",
       "462                  0.703704                   0.529412   \n",
       "463                  0.407407                   0.676471   \n",
       "464                  0.222222                   0.382353   \n",
       "465                  0.629630                   0.647059   \n",
       "466                  0.259259                   0.264706   \n",
       "467                  0.444444                   0.382353   \n",
       "468                  0.185185                   0.352941   \n",
       "469                  0.740741                   0.441176   \n",
       "470                  0.740741                   0.411765   \n",
       "471                  0.481481                   0.529412   \n",
       "472                  0.592593                   0.470588   \n",
       "473                  0.592593                   0.647059   \n",
       "474                  0.592593                   0.705882   \n",
       "475                  0.481481                   0.441176   \n",
       "476                  0.666667                   0.441176   \n",
       "477                  0.333333                   0.470588   \n",
       "478                  0.592593                   0.382353   \n",
       "479                  0.962963                   0.794118   \n",
       "480                  0.888889                   0.411765   \n",
       "481                  0.666667                   0.735294   \n",
       "482                  0.518519                   0.470588   \n",
       "483                  0.296296                   0.529412   \n",
       "484                  0.185185                   0.382353   \n",
       "485                  0.518519                   0.470588   \n",
       "486                  0.740741                   0.294118   \n",
       "\n",
       "     superiortemporal_MeanCurv  supramarginal_MeanCurv  \\\n",
       "0                     0.593750                0.433333   \n",
       "1                     0.656250                0.333333   \n",
       "2                     0.562500                0.600000   \n",
       "3                     0.625000                0.733333   \n",
       "4                     0.468750                0.333333   \n",
       "5                     0.625000                0.433333   \n",
       "6                     0.406250                0.566667   \n",
       "7                     0.312500                0.266667   \n",
       "8                     0.625000                0.266667   \n",
       "9                     0.593750                0.400000   \n",
       "10                    0.843750                0.900000   \n",
       "11                    0.531250                0.400000   \n",
       "12                    0.593750                0.533333   \n",
       "13                    0.562500                0.533333   \n",
       "14                    0.531250                0.633333   \n",
       "15                    0.531250                0.533333   \n",
       "16                    0.687500                0.266667   \n",
       "17                    0.937500                0.533333   \n",
       "18                    0.187500                0.266667   \n",
       "19                    0.500000                0.333333   \n",
       "20                    0.531250                0.233333   \n",
       "21                    0.468750                0.166667   \n",
       "22                    0.562500                0.300000   \n",
       "23                    0.687500                0.300000   \n",
       "24                    0.406250                0.533333   \n",
       "25                    0.687500                0.533333   \n",
       "26                    0.312500                0.133333   \n",
       "27                    0.281250                0.466667   \n",
       "28                    0.562500                0.200000   \n",
       "29                    0.187500                0.466667   \n",
       "..                         ...                     ...   \n",
       "457                   0.741935                0.636364   \n",
       "458                   0.290323                0.696970   \n",
       "459                   0.516129                0.272727   \n",
       "460                   0.225806                0.393939   \n",
       "461                   0.580645                0.575758   \n",
       "462                   0.838710                0.484848   \n",
       "463                   0.258065                0.303030   \n",
       "464                   0.258065                0.333333   \n",
       "465                   0.483871                0.636364   \n",
       "466                   0.225806                0.424242   \n",
       "467                   0.387097                0.424242   \n",
       "468                   0.516129                0.333333   \n",
       "469                   0.709677                0.727273   \n",
       "470                   0.516129                0.212121   \n",
       "471                   0.548387                0.515152   \n",
       "472                   0.451613                0.636364   \n",
       "473                   0.451613                0.484848   \n",
       "474                   0.290323                0.212121   \n",
       "475                   0.709677                0.363636   \n",
       "476                   0.645161                0.575758   \n",
       "477                   0.516129                0.272727   \n",
       "478                   0.677419                0.333333   \n",
       "479                   0.967742                0.636364   \n",
       "480                   0.741935                0.545455   \n",
       "481                   0.516129                0.636364   \n",
       "482                   0.322581                0.545455   \n",
       "483                   0.258065                0.484848   \n",
       "484                   0.161290                0.060606   \n",
       "485                   0.580645                0.818182   \n",
       "486                   0.451613                0.363636   \n",
       "\n",
       "     transversetemporal_MeanCurv  insula_MeanCurv  \n",
       "0                       0.444444         0.486486  \n",
       "1                       0.583333         0.675676  \n",
       "2                       0.583333         0.135135  \n",
       "3                       0.180556         0.297297  \n",
       "4                       0.680556         0.378378  \n",
       "5                       0.250000         0.405405  \n",
       "6                       0.597222         0.243243  \n",
       "7                       0.541667         0.648649  \n",
       "8                       0.000000         0.621622  \n",
       "9                       0.583333         0.351351  \n",
       "10                      0.402778         0.675676  \n",
       "11                      0.638889         0.540541  \n",
       "12                      0.472222         0.675676  \n",
       "13                      0.500000         0.459459  \n",
       "14                      0.527778         0.513514  \n",
       "15                      0.708333         0.540541  \n",
       "16                      0.541667         0.351351  \n",
       "17                      0.708333         0.216216  \n",
       "18                      0.263889         0.324324  \n",
       "19                      0.652778         0.459459  \n",
       "20                      0.500000         0.324324  \n",
       "21                      0.625000         0.432432  \n",
       "22                      0.250000         0.216216  \n",
       "23                      0.319444         0.945946  \n",
       "24                      0.444444         0.486486  \n",
       "25                      0.333333         0.513514  \n",
       "26                      0.250000         0.297297  \n",
       "27                      0.111111         0.594595  \n",
       "28                      0.361111         0.189189  \n",
       "29                      0.388889         0.189189  \n",
       "..                           ...              ...  \n",
       "457                     0.740260         0.615385  \n",
       "458                     0.675325         0.692308  \n",
       "459                     0.350649         0.435897  \n",
       "460                     0.441558         0.282051  \n",
       "461                     0.220779         0.487179  \n",
       "462                     0.415584         0.512821  \n",
       "463                     0.857143         0.615385  \n",
       "464                     0.532468         0.435897  \n",
       "465                     0.545455         0.461538  \n",
       "466                     0.649351         0.589744  \n",
       "467                     0.636364         0.435897  \n",
       "468                     0.415584         0.410256  \n",
       "469                     0.090909         0.692308  \n",
       "470                     0.233766         0.743590  \n",
       "471                     0.467532         0.589744  \n",
       "472                     0.389610         0.512821  \n",
       "473                     0.246753         0.538462  \n",
       "474                     0.467532         0.307692  \n",
       "475                     0.493506         0.435897  \n",
       "476                     0.493506         0.615385  \n",
       "477                     0.519481         0.230769  \n",
       "478                     0.376623         0.307692  \n",
       "479                     0.727273         0.615385  \n",
       "480                     0.896104         0.410256  \n",
       "481                     0.454545         0.692308  \n",
       "482                     0.207792         0.307692  \n",
       "483                     0.454545         0.205128  \n",
       "484                     0.324675         0.333333  \n",
       "485                     0.532468         0.794872  \n",
       "486                     0.597403         0.794872  \n",
       "\n",
       "[487 rows x 318 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm = pd.concat([data_man_norm, data_woman_norm], axis=0, ignore_index=True)\n",
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_shuffled0 = shuffle(data_norm, random_state=7)\n",
    "data_shuffled0 = data_shuffled0.reset_index(drop=True)\n",
    "y0 = data_shuffled0.grupa\n",
    "X0 = data_shuffled0.drop(['grupa'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-test for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "smoker = data_shuffled0[data_shuffled0['grupa']== 1]\n",
    "nsmoker = data_shuffled0[data_shuffled0['grupa']== 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 304)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smoker), len(nsmoker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_stats=[]\n",
    "p_value=[]\n",
    "for i in list(data_shuffled0)[3:250]:\n",
    "    #print(i)\n",
    "    #print(ttest_ind(smoker[i], nsmoker[i]))\n",
    "    test=ttest_ind(smoker[i], nsmoker[i])\n",
    "    t_stats.append(test[0])\n",
    "    p_value.append(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data frame with variables and scores, sorted\n",
    "t_test = pd.DataFrame({'variable': list(data_shuffled0)[3:250], 't_statistic': t_stats, 'p_value':p_value})\n",
    "t_test = t_test.sort_values(by=['p_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_test_list= t_test['variable'][1:15].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def feature_selector(X0, x_val, y0, y_val, test_method, classifier_method, test_size=0.2, num_iters=1000):\n",
    "    \"\"\"Function that will plot how adding next features influence classifier score\n",
    "    :param test_method: given order of features\n",
    "    :param classifier_method: classifier\"\"\"\n",
    "    \n",
    "    scores_big_array = []\n",
    "    for n_iters in range(0, num_iters):\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X0, y0, test_size=test_size)#, random_state=1)\n",
    "\n",
    "        scores = []\n",
    "        for i in range(1, len(test_method)):\n",
    "            classifier_method.fit(X0[test_method[0:i]['variable']], y)\n",
    "            score = classifier_method.score(x_val[test_method[0:i]['variable']], y_val)\n",
    "            scores.append(score)\n",
    "        scores_big_array.append(scores)\n",
    "    scores_big_array_np = np.array(scores_big_array)\n",
    "    \n",
    "    # plot mean values\n",
    "    plt.plot(range(1, 223), scores_big_array_np.mean(axis=0), color=\"black\")\n",
    "    plt.title(\"Accuracy of LogReg with t-test feature selection\")\n",
    "    plt.xlabel(\"Number Of variables\")\n",
    "    plt.ylabel(\"Accuracy Score\")\n",
    "    print(\"Mean accuracy values for different number of features ={}\".format(scores_big_array_np.mean(axis=0)))\n",
    "    return scores_big_array_np\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "feature_selector() missing 2 required positional arguments: 'test_method' and 'classifier_method'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-5bd56dbd2ff7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Get accuracy of feature selection for logreg and t_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscores_big_array_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: feature_selector() missing 2 required positional arguments: 'test_method' and 'classifier_method'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Returns vector of acc results with increasing number of features\n",
    "logreg = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "# Get accuracy of feature selection for logreg and t_test\n",
    "scores_big_array_np = feature_selector(X0, y0, t_test, logreg, test_size=0.2, num_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_big_array_np.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Total cortical gray matter volume (mm3)',\n",
       " ' Left hemisphere cortical gray matter volume (mm3)',\n",
       " ' Total gray matter volume (mm3)',\n",
       " ' Right hemisphere cortical gray matter volume (mm3)']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "feature_scores = mutual_info_classif(X0, y0)\n",
    "\n",
    "# data frame with variables and scores, sorted\n",
    "inf_gain= pd.DataFrame({'variable': list(X0), 'score': -np.sort(-feature_scores)})\n",
    "\n",
    "inf_gain_list = inf_gain['variable'][1:15].tolist()\n",
    "\n",
    "list(set(t_test_list) & set(inf_gain_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy of feature selection for logreg and information gain\n",
    "scores_big_array_np = feature_selector(X0, y0, inf_gain, logreg, test_size=0.2, num_iters=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = RandomForestClassifier(n_estimators=100,\n",
    "                              random_state=0)\n",
    "\n",
    "model = forest.fit(X0, y0)\n",
    "importances = model.feature_importances_\n",
    "\n",
    "# data frame with variables and scores, sorted\n",
    "rf_imp = pd.DataFrame({'variable': list(X0), 'score': -np.sort(-importances)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_imp_list = rf_imp['variable'][1:15].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(rf_imp_list) & set(t_test_list) & set(inf_gain_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy of feature selection for logreg and random forest feature importance\n",
    "scores_big_array_np = feature_selector(X0, y0, rf_imp, logreg, test_size=0.2, num_iters=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get accuracy of feature selection for random forest and random forest feature importance\n",
    "#scores_big_array_np = feature_selector(X0, y0, rf_imp, forest, test_size=0.2, num_iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy of feature selection for random forest and information gain importance\n",
    "scores_big_array_np = feature_selector(X0, y0, inf_gain, forest, test_size=0.2, num_iters=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "principalComponents = pca.fit_transform(X0)\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kpca = KernelPCA(kernel=\"rbf\", fit_inverse_transform=True, gamma=10)\n",
    "X_kpca = kpca.fit_transform(X0)\n",
    "X_back = kpca.inverse_transform(X_kpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kpca_sig=KernelPCA(kernel=\"sigmoid\", fit_inverse_transform=True, gamma=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kpca_poly=KernelPCA(kernel=\"poly\", degree = 3, fit_inverse_transform=True, gamma=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kernel_Pca(ker):\n",
    "    kpca = KernelPCA(n_components=4, kernel=ker, gamma=15)\n",
    "    x_kpca = kpca.fit_transform(X0)\n",
    "    kpca_transform = kpca.fit_transform(X0)\n",
    "    explained_variance = np.var(kpca_transform, axis=0)\n",
    "    ev = explained_variance / np.sum(explained_variance)\n",
    "\n",
    "    #--------- Bar Graph for Explained Variance Ratio ------------\n",
    "    plt.bar([1,2,3,4],list(ev*100),label='Principal Components',color='b')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Principal Components ')\n",
    "    #----------------------\n",
    "    n=list(ev*100)\n",
    "    pc=[]\n",
    "    for i in range(len(n)):\n",
    "            n[i]=round(n[i],4)\n",
    "            pc.append('PC-'+str(i+1)+'('+str(n[i])+')')\n",
    "\n",
    "    #----------------------\n",
    "    plt.xticks([1,2,3,4],pc, fontsize=7, rotation=30)\n",
    "    plt.ylabel('Variance Ratio')\n",
    "    plt.title('Variance Ratio of MRI data using kernel:'+str(ker))\n",
    "    plt.show()\n",
    "    #---------------------------------------------------\n",
    "    # *Since the initial 2 principal components have high variance.\n",
    "    #   so, we select pc-1 and pc-2.\n",
    "    #---------------------------------------------------\n",
    "    kpca = KernelPCA(n_components=2, kernel=ker, gamma=15)\n",
    "    x_kpca = kpca.fit_transform(X0)\n",
    "    principalComponents = kpca.fit_transform(X0)\n",
    "#QWQdeeqREdqarde\n",
    "    principalDf = pd.DataFrame(data = principalComponents\n",
    "                 , columns = ['PC-1', 'PC-2'])\n",
    "    # Adding lables\n",
    "    finalDf = pd.concat([principalDf, data_shuffled0[['grupa']]], axis = 1)\n",
    "    # Plotting pc1 & pc2\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('PC-1', fontsize = 15)\n",
    "    ax.set_ylabel('PC-2', fontsize = 15)\n",
    "    ax.set_title('KPCA on MRI data using kernel:'+str(ker), fontsize = 20)\n",
    "    targets = [1, 0]\n",
    "    colors = ['r', 'g']\n",
    "    for target, color in zip(targets,colors):\n",
    "        indicesToKeep = finalDf['grupa'] == target\n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'PC-1']\n",
    "                   , finalDf.loc[indicesToKeep, 'PC-2']\n",
    "                   , c = color\n",
    "                   , s = 30)\n",
    "    ax.legend(targets)\n",
    "    ax.grid()\n",
    "    plt.show() # FOR SHOWING THE PLOT\n",
    "    #------------------- SAVING DATA INTO CSV FILE ------------\n",
    "    #finalDf.to_csv('iris_after_KPCA_using_'+str(ker)+'.csv')\n",
    "\n",
    "\n",
    "#------------------------------------------------------\n",
    "k=['linear','rbf','poly','sigmoid' ]\n",
    "for i in k:\n",
    "    Kernel_Pca(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redefine data to select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Right hemisphere cortical gray matter volume (mm3)\n",
    "#Total cortical gray matter volume (mm3)\n",
    "#Mask Volume (mm3)\n",
    "#Left hemisphere cortical gray matter volume (mm3)\n",
    "#Total gray matter volume (mm3)\n",
    "#Supratentorial volume (mm3)\n",
    "# Brain Segmentation Volume Without Ventricles (mm3)\n",
    "# Estimated Total Intracranial Volume (mm3)\n",
    "                                             \n",
    "data_red= data_norm\n",
    "#data_red = data[['grupa', ' Right hemisphere cortical gray matter volume (mm3)', ' Total cortical gray matter volume (mm3)', ' Mask Volume (mm3)', ' Left hemisphere cortical gray matter volume (mm3)', ' Total gray matter volume (mm3)', ' Supratentorial volume (mm3)', ' Brain Segmentation Volume Without Ventricles (mm3)', ' Estimated Total Intracranial Volume (mm3)']]                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Classifier model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "def run_k_fold(classifier, X, y, k = 10):\n",
    "    kf = KFold (n_splits = k,random_state=7)\n",
    "    kf.get_n_splits(X)\n",
    "    \n",
    "    accuracy_set=[]\n",
    "    roc_score_set=[]\n",
    "    #precision_set =[]\n",
    "    yscore_np = -np.ones(shape=y.shape)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        #predictions = rfc.predict(X_test)\n",
    "        score = classifier.score(X_test, y_test)\n",
    "        accuracy_set.append(score)\n",
    "        \n",
    "        if classifier == svmc:\n",
    "            print(classifier.decision_function(X_test))\n",
    "            yscore_np[test_index] = classifier.decision_function(X_test)\n",
    "        else:\n",
    "            #print(classifier.predict_proba(X_test))\n",
    "            yscore_np[test_index] = classifier.predict_proba(X_test)[:,0]\n",
    "        #precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, classifier.predict(X_test))\n",
    "        #print (auc(false_positive_rate, true_positive_rate))\n",
    "        rscore = auc(false_positive_rate, true_positive_rate)\n",
    "        roc_score_set.append(rscore)\n",
    "\n",
    "    #print (roc_auc_score(y, rfc.predict(X)))\n",
    "    average_precision = average_precision_score(y, yscore_np)\n",
    "\n",
    "    print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y, yscore_np)\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "          average_precision))\n",
    "    \n",
    "    \n",
    "    avg_acc = sum(accuracy_set)/len(accuracy_set)\n",
    "    avg_auc = sum(roc_score_set)/len(roc_score_set)\n",
    "    print (\"Average accuracy score score %f\" % avg_acc)\n",
    "    print (\"Average ROC AUC score %f\" % avg_auc)\n",
    "    return avg_acc, avg_auc, average_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOCV model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_loocv(classifier):\n",
    "    loo = LeaveOneOut()\n",
    "    tot_acc=[]\n",
    "    for train_index, test_index in loo.split(X):\n",
    "            #print(\"train:\", train_index, \"validation:\", test_index)\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            classifier.fit(X_train, y_train)\n",
    "\n",
    "            score = logreg.score(X_test, y_test)\n",
    "            tot_acc.append(score)\n",
    "    print(sum(tot_acc)/len(tot_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle data and split to target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data_shuffled = shuffle(data_red)\n",
    "data_shuffled = data_shuffled.reset_index(drop=True)\n",
    "y = data_shuffled.grupa\n",
    "X = data_shuffled.drop(['grupa'], axis=1)\n",
    "\n",
    "X= pd.DataFrame(min_max_scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "X, X_val, y, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "X=np.array(X)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(solver = 'lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOOCV logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_loocv(logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold CV logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_k_fold(logreg, X, y, 3)\n",
    "run_k_fold(logreg, X, y, 5)\n",
    "run_k_fold(logreg, X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svmc = svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOOCV SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loocv(svmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold CV linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_k_fold(svmc,X, y, 3)\n",
    "run_k_fold(svmc, X, y, 5)\n",
    "run_k_fold(svmc,X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kernel_SVM(ker, X, y, k):\n",
    "    ker_svm = svm.NuSVC(kernel=ker, gamma=15)\n",
    "    print (ker, k)\n",
    "    run_k_fold(ker_svm, X, y, k)\n",
    "\n",
    "\n",
    "k=['linear', 'poly', 'rbf', 'sigmoid']\n",
    "for i in k:\n",
    "    Kernel_SVM(i, X, y, 3)\n",
    "    Kernel_SVM(i, X, y, 3)\n",
    "    Kernel_SVM(i, X, y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOOCV framework\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_loocv(rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold  random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_k_fold(rfc, X, y, 3)\n",
    "run_k_fold(rfc, X, y, 5)\n",
    "run_k_fold(rfc, X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "#model = XGBClassifier()\n",
    "#model.fit(X, y)\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run_k_fold(model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature importance\n",
    "#print(model.feature_importances_)\n",
    "# plot\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.bar(range(len(model.feature_importances_)), model.feature_importances_)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring classification performance \n",
    "\n",
    "ROC curve, AUC and ACC (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on validation set\n",
    "\n",
    "print(\"Accuracy score score for validation set (logistic regression) %f\" % (logreg.score(X_val, y_val)))\n",
    "\n",
    "print(\"Accuracy score score for validation set (SVM) %f\" % (svmc.score(X_val, y_val)))\n",
    "\n",
    "print(\"Accuracy score score for validation set  (RF) %f\" % (rfc.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete function for testing classification performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funtion for running the whole calssification process, after applying feature selection , \n",
    "# and with varying validation set ratios\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def run_classification( data, classifier, feature_selector_list, k = 10, val_ratio = 0.2, nr_of_feat = 20):\n",
    "    # apply feature selection criteria with specified number of features\n",
    "    data_reduced= data[['grupa'] + feature_selector_list[1:nr_of_feat]]\n",
    "    \n",
    "    \n",
    "    # shuffle data \n",
    "    data_shuffled = shuffle(data_reduced, random_state=7)\n",
    "    data_shuffled = data_shuffled.reset_index(drop=True)\n",
    "    y = data_shuffled.grupa\n",
    "    X = data_shuffled.drop(['grupa'], axis=1)\n",
    "\n",
    "    \n",
    "    # split data into train+test and validation sets\n",
    "    X, X_val, y, y_val = train_test_split(X, y, test_size=val_ratio, random_state=1)\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    #grid search for best model meta parameters for the classifier \n",
    "    param_rf = {'bootstrap': [True, False],\n",
    "                'n_estimators': [50, 100, 150]}\n",
    "    param_svm = {'kernel': ['rbf'], 'C':[1, 10, 100]}\n",
    "    param_lr = {'C':[1, 10, 100]}\n",
    "    param_xgb = {'xgb.XGBClassifier': [5, 10, 25], 'n_estimators': [50,100,150], 'learning_rate': [0.05, 0.1]}\n",
    "    \n",
    "    if classifier == random_forest:\n",
    "        clf = GridSearchCV(classifier, param_rf, cv=5)\n",
    "    if classifier == svmm:\n",
    "        clf = GridSearchCV(classifier, param_svm, cv=5)\n",
    "    if classifier == lr:\n",
    "        clf = GridSearchCV(classifier, param_lr, cv=5)\n",
    "    #if classifier == xgbc:\n",
    "    #    clf = GridSearchCV(classifier, param_xgb, cv=5)\n",
    "    clf_grid = clf.fit(X, y)\n",
    "    \n",
    "    # run model classification\n",
    "    avg_acc, avg_roc, average_precision = run_k_fold(clf_grid, X, y)\n",
    "    \n",
    "    # calculate validation accuracy (accuracy of trained model on the data initially left out)\n",
    "    val_acc = clf_grid.score(X_val, y_val)\n",
    "    \n",
    "    #return average accuracy on test sets, average auc score on test sets, and validation score\n",
    "    return val_acc, average_precision # avg_roc, val_acc\n",
    "    #print (avg_acc, avg_roc, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-cc46a37ea346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Classifiers:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrandom_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msvmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#xgbc = XGBClassifier()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svm' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Feature selection feature lists:\n",
    "fs_list = [rf_imp_list, t_test_list, inf_gain_list]\n",
    "\n",
    "# Classifiers:\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "svmm = svm.SVC()\n",
    "lr = LogisticRegression(solver = 'lbfgs')\n",
    "#xgbc = XGBClassifier()\n",
    "\n",
    "clasf = [random_forest, svmc, lr ]#,xgbc ]\n",
    "\n",
    "# Validation set ratio\n",
    "val_set = [0.1, 0.2, 0.25]\n",
    "\n",
    "# number of features\n",
    "feat_nr = [5, 10, 15, 20]\n",
    "\n",
    "# k-fold\n",
    "k_fold = [3,5,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run_classification( data_norm, random_forest, 10, rf_imp_list, val_ratio = 0.2, nr_of_feat = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run through all combinations i a loop (feature selection + classifier)\n",
    "# features set at 20, k fold at 10\n",
    "arr_acc = np.array([[[0.0 for i in val_set] for j in fs_list] for k in clasf])\n",
    "arr_prec = np.array([[[0.0 for i in val_set] for j in fs_list] for k in clasf])\n",
    " \n",
    "for i,c in enumerate(clasf):\n",
    "    for j,f in enumerate(fs_list):\n",
    "        for k,v in enumerate(val_set):\n",
    "            print( i,c,j,f,k,v)\n",
    "            arr_acc[i,j,k], arr_prec[i,j,k] = run_classification(data_norm, c, f, val_ratio = v)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = np.array([[[0.0 for i in val_set] for j in fs_list] for k in clasf])\n",
    " \n",
    "for i,c in enumerate(clasf):\n",
    "    for j,f in enumerate(fs_list):\n",
    "        for k,v in enumerate(val_set):\n",
    "            print( i,c,j,f,k,v)\n",
    "            arr2[i,j,k] = run_classification(data_norm, c, f, val_ratio = v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running 3x3 classification, with different feature selectors and different classifiers\n",
    "# TODO: Remember to pass models after grid search (the ones with the parameters that gives the best results )\n",
    "#run_classification( data_norm, random_forest, 10, rf_imp_list, val_ratio = 0.2, nr_of_feat = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search for best model meta parameters for the classifier \n",
    "\n",
    "def gridsearch_fit(classifier, X, y):\n",
    "    param_rf = {'bootstrap': [True, False],\n",
    "            'n_estimators': [50, 100, 150]}\n",
    "    param_svm = {'kernel': ['rbf'], 'C':[1, 10, 100]}\n",
    "    param_lr = {'C':[1, 10, 100]}\n",
    "    param_xgb = {'xgb.XGBClassifier': [5, 10, 25], 'n_estimators': [50,100,150], 'learning_rate': [0.05, 0.1]}\n",
    "    \n",
    "    if classifier == rf_clf:\n",
    "        clf = GridSearchCV(classifier, param_rf, cv=5)\n",
    "    if classifier == svm_clf:\n",
    "        clf = GridSearchCV(classifier, param_svm, cv=5)\n",
    "    if classifier == lr_clf:\n",
    "        clf = GridSearchCV(classifier, param_lr, cv=5)\n",
    "    #if classifier == xgbc:\n",
    "    #    clf = GridSearchCV(classifier, param_xgb, cv=5)\n",
    "    clf_grid = clf.fit(X, y)\n",
    "    return clf_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into set for train/test and independent validation set\n",
    "\n",
    "#data_reduced= data[['grupa'] + feature_selector_list[1:nr_of_feat]]\n",
    "\n",
    "\n",
    "# shuffle data \n",
    "data_shuffled = shuffle(data_norm, random_state=11)\n",
    "data_shuffled = data_shuffled.reset_index(drop=True)\n",
    "y = data_shuffled.grupa\n",
    "X = data_shuffled.drop(['grupa'], axis=1)\n",
    "\n",
    "\n",
    "# split data into train+test and validation sets\n",
    "X, X_val, y, y_val = train_test_split(X, y, test_size=.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "svm_clf = svm.SVC()\n",
    "lr_clf = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "classifiers = [rf_clf, svm_clf, lr_clf ]\n",
    "\n",
    "for c in classifiers:\n",
    "    c = gridsearch_fit(c, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers\n",
    "\n",
    "fs_list = [rf_imp_list, t_test_list, inf_gain_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=0,\n",
      "            verbose=0, warm_start=False) 0 [' Brain Segmentation Volume Without Ventricles (mm3)', ' Brain Segmentation Volume Without Ventricles from Surf (mm3)', ' Volume of ventricles and choroid plexus (mm3)', ' Left hemisphere cortical gray matter volume (mm3)', ' Right hemisphere cortical gray matter volume (mm3)', ' Total cortical gray matter volume (mm3)', ' Left hemisphere cerebral white matter volume (mm3)', ' Right hemisphere cerebral white matter volume (mm3)', ' Total cerebral white matter volume (mm3)', ' Subcortical gray matter volume (mm3)', ' Total gray matter volume (mm3)', ' Supratentorial volume (mm3)', ' Supratentorial volume (mm3)2', ' Supratentorial volume voxel count (mm3)']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-313edc8a7e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# acc_with_features[i,j] = feature_selector(X0, y0, f, c, test_size=0.2, num_iters=1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtmp_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mclf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0macc_with_features_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-159-d7ee1f40ac1a>\u001b[0m in \u001b[0;36mfeature_selector\u001b[0;34m(X0, x_val, y0, y_val, test_method, classifier_method, test_size, num_iters)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mclassifier_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_method\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_method\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'variable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "acc_with_features = np.array([[0.0 for j in fs_list] for k in classifiers])\n",
    "acc_with_features_list = []  #np.array([[0.0 for j in fs_list] for k in clasf])\n",
    "#def feature_selector(X0, x_val, y0, y_val, test_method, classifier_method, test_size=0.2, num_iters=1000):\n",
    "\n",
    "clf_list = []\n",
    "for i,c in enumerate(classifiers):\n",
    "    for j,f in enumerate(fs_list):\n",
    "        print( i,c,j,f)\n",
    "        #arr2[i,j,k] = run_classification(data_norm, c, f, val_ratio = v)\n",
    "\n",
    "        # acc_with_features[i,j] = feature_selector(X0, y0, f, c, test_size=0.2, num_iters=1000)\n",
    "        tmp_res = feature_selector(X, X_val, y, y_val, f, c, test_size=0.2, num_iters=10)\n",
    "        clf_list.append(tmp_res)\n",
    "    acc_with_features_list.append(clf_list)\n",
    "# get final results to the array (should be 4d)\n",
    "big_arr_to_graph = np.array(acc_with_features_list)\n",
    "# now, let's get mean of the last dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-175-f25c8151f88d>, line 16)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-175-f25c8151f88d>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    scores = []\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#def feature_selector(X0, x_val, y0, y_val, test_method, classifier_method, test_size=0.2, num_iters=1000):\n",
    "#tmp_res = feature_selector(X, X_val, y, y_val, f, c, test_size=0.2, num_iters=10)\n",
    "X0 = X\n",
    "x_val=X_val\n",
    "y0=y\n",
    "test_method=fs_list[0]\n",
    "classifier_method = classifiers[0]\n",
    "num_iters=10\n",
    "test_size=0.2\n",
    "scores_big_array = []\n",
    "n_iters = 0\n",
    "i = 0\n",
    "#for n_iters in range(0, num_iters):\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X0, y0, test_size=test_size)#, random_state=1)\n",
    "\n",
    "    scores = []\n",
    " #   for i in range(1, len(test_method)):\n",
    "        classifier_method.fit(X0[test_method[0:i]['variable']], y)\n",
    "        score = classifier_method.score(x_val[test_method[0:i]['variable']], y_val)\n",
    "        scores.append(score)\n",
    "    scores_big_array.append(scores)\n",
    "scores_big_array_np = np.array(scores_big_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    classifier_method.fit(X0[test_method[0:i]['variable']], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Brain Segmentation Volume Without Ventricles (mm3)',\n",
       " ' Brain Segmentation Volume Without Ventricles from Surf (mm3)',\n",
       " ' Volume of ventricles and choroid plexus (mm3)',\n",
       " ' Left hemisphere cortical gray matter volume (mm3)',\n",
       " ' Right hemisphere cortical gray matter volume (mm3)',\n",
       " ' Total cortical gray matter volume (mm3)',\n",
       " ' Left hemisphere cerebral white matter volume (mm3)',\n",
       " ' Right hemisphere cerebral white matter volume (mm3)',\n",
       " ' Total cerebral white matter volume (mm3)',\n",
       " ' Subcortical gray matter volume (mm3)']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_method[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
